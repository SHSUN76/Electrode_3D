# 전극 구조 자동생성기 - 기술 스택 상세 문서

> **문서 버전**: 1.0
> **작성일**: 2025년 1월
> **목적**: 배터리 전극 미세구조 자동 생성 시스템의 기술 스택 상세 가이드

---

## 목차

1. [Part 1: SliceGAN 아키텍처 상세 구현 방법](#part-1-slicegan-아키텍처-상세-구현-방법)
2. [Part 2: 프로젝트 초기 구조 설계](#part-2-프로젝트-초기-구조-설계)
3. [Part 3: 데이터 수집/전처리 파이프라인 설계](#part-3-데이터-수집전처리-파이프라인-설계)
4. [Part 4: Blender + COMSOL 연계 워크플로우](#part-4-blender--comsol-연계-워크플로우)

---

# Part 1: SliceGAN 아키텍처 상세 구현 방법

## 1.1 개요

SliceGAN은 2D 이미지로부터 3D 미세구조를 생성하는 딥러닝 모델입니다. 기존 GAN이 2D 이미지 생성에 초점을 맞춘 반면, SliceGAN은 3D 볼륨 데이터를 생성하면서도 2D 슬라이스만으로 학습이 가능한 혁신적인 구조를 가지고 있습니다.

### 핵심 아이디어

```
┌─────────────────────────────────────────────────────────────────┐
│                      SliceGAN 핵심 개념                          │
├─────────────────────────────────────────────────────────────────┤
│                                                                 │
│   [2D Training Images]                                          │
│          │                                                      │
│          ▼                                                      │
│   ┌─────────────┐    ┌─────────────┐    ┌─────────────┐        │
│   │   Slicer    │◄───│ 3D Generator│◄───│ Latent      │        │
│   │ (x,y,z축)   │    │             │    │ Variables   │        │
│   └──────┬──────┘    └─────────────┘    └─────────────┘        │
│          │                                                      │
│          ▼                                                      │
│   ┌─────────────┐                                               │
│   │   Critic    │──► Real vs Fake 판별                          │
│   │(Discriminator)│                                              │
│   └─────────────┘                                               │
│                                                                 │
└─────────────────────────────────────────────────────────────────┘
```

### 배터리 전극 적용의 장점

| 특징 | 설명 |
|------|------|
| **2D 학습** | FIB-SEM의 2D 단면 이미지만으로 학습 가능 |
| **다상 구조** | 활물질, 기공, 바인더 등 다중 상(phase) 표현 |
| **통계적 일관성** | 원본 미세구조의 통계적 특성 유지 |
| **확장성** | 임의 크기의 3D 구조 생성 가능 |

---

## 1.2 핵심 구성요소

### 1.2.1 3D Generator (생성자)

Generator는 저차원 잠재 공간(latent space)에서 고차원 3D 볼륨을 생성합니다.

**아키텍처 사양:**

| 레이어 | 입력 크기 | 출력 크기 | 커널 | 스트라이드 |
|--------|-----------|-----------|------|------------|
| Input | 64 × 4 × 4 × 4 | - | - | - |
| ConvT1 | 64 × 4 × 4 × 4 | 512 × 8 × 8 × 8 | 4 | 2 |
| ConvT2 | 512 × 8 × 8 × 8 | 256 × 16 × 16 × 16 | 4 | 2 |
| ConvT3 | 256 × 16 × 16 × 16 | 128 × 32 × 32 × 32 | 4 | 2 |
| ConvT4 | 128 × 32 × 32 × 32 | 64 × 64 × 64 × 64 | 4 | 2 |
| ConvT5 | 64 × 64 × 64 × 64 | n_phases × 64 × 64 × 64 | 3 | 1 |

**PyTorch 구현:**

```python
import torch
import torch.nn as nn

class Generator3D(nn.Module):
    """
    SliceGAN 3D Generator

    입력: z (batch, 64, 4, 4, 4) - latent variables
    출력: (batch, n_phases, 64, 64, 64) - 3D voxel volume
    """

    def __init__(self, n_phases=3, nz=64, ngf=64):
        super(Generator3D, self).__init__()

        self.n_phases = n_phases

        # Transpose Convolution 레이어 정의
        self.main = nn.Sequential(
            # Layer 1: 4x4x4 -> 8x8x8
            nn.ConvTranspose3d(nz, ngf * 8, 4, 2, 1, bias=False),
            nn.BatchNorm3d(ngf * 8),
            nn.ReLU(True),

            # Layer 2: 8x8x8 -> 16x16x16
            nn.ConvTranspose3d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),
            nn.BatchNorm3d(ngf * 4),
            nn.ReLU(True),

            # Layer 3: 16x16x16 -> 32x32x32
            nn.ConvTranspose3d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),
            nn.BatchNorm3d(ngf * 2),
            nn.ReLU(True),

            # Layer 4: 32x32x32 -> 64x64x64
            nn.ConvTranspose3d(ngf * 2, ngf, 4, 2, 1, bias=False),
            nn.BatchNorm3d(ngf),
            nn.ReLU(True),

            # Layer 5 (Output): 64x64x64 -> 64x64x64 x n_phases
            nn.ConvTranspose3d(ngf, n_phases, 3, 1, 1, bias=False),
            nn.Softmax(dim=1)  # 다상(multi-phase) 분류
        )

    def forward(self, z):
        return self.main(z)
```

### 1.2.2 Critic (판별자)

SliceGAN은 WGAN-GP를 사용하므로 Discriminator 대신 Critic이라고 부릅니다.

**아키텍처 사양:**

| 레이어 | 입력 크기 | 출력 크기 | 커널 | 스트라이드 |
|--------|-----------|-----------|------|------------|
| Conv1 | n_phases × 64 × 64 | 64 × 32 × 32 | 4 | 2 |
| Conv2 | 64 × 32 × 32 | 128 × 16 × 16 | 4 | 2 |
| Conv3 | 128 × 16 × 16 | 256 × 8 × 8 | 4 | 2 |
| Conv4 | 256 × 8 × 8 | 512 × 4 × 4 | 4 | 2 |
| Conv5 | 512 × 4 × 4 | 1 × 1 × 1 | 4 | 1 |

**PyTorch 구현:**

```python
class Critic2D(nn.Module):
    """
    SliceGAN 2D Critic (Discriminator)

    입력: 2D slice (batch, n_phases, 64, 64)
    출력: Wasserstein distance score
    """

    def __init__(self, n_phases=3, ndf=64):
        super(Critic2D, self).__init__()

        self.main = nn.Sequential(
            # Layer 1: 64x64 -> 32x32
            nn.Conv2d(n_phases, ndf, 4, 2, 1, bias=False),
            nn.LeakyReLU(0.2, inplace=True),

            # Layer 2: 32x32 -> 16x16
            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),
            nn.LayerNorm([ndf * 2, 16, 16]),
            nn.LeakyReLU(0.2, inplace=True),

            # Layer 3: 16x16 -> 8x8
            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),
            nn.LayerNorm([ndf * 4, 8, 8]),
            nn.LeakyReLU(0.2, inplace=True),

            # Layer 4: 8x8 -> 4x4
            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),
            nn.LayerNorm([ndf * 8, 4, 4]),
            nn.LeakyReLU(0.2, inplace=True),

            # Layer 5: 4x4 -> 1x1
            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False)
        )

    def forward(self, x):
        return self.main(x).view(-1, 1)
```

### 1.2.3 Slicer (슬라이서)

Slicer는 3D 볼륨에서 2D 슬라이스를 추출하는 모듈입니다.

```python
class Slicer:
    """
    3D 볼륨에서 2D 슬라이스 추출

    세 축(x, y, z)에서 무작위 위치의 슬라이스를 추출하여
    Critic이 각 방향에서 구조의 일관성을 평가할 수 있게 함
    """

    @staticmethod
    def slice_volume(volume, axis='z', position=None):
        """
        Args:
            volume: (batch, channels, D, H, W) 형태의 3D 텐서
            axis: 슬라이싱 축 ('x', 'y', 'z')
            position: 슬라이스 위치 (None이면 랜덤)

        Returns:
            2D 슬라이스 (batch, channels, H, W)
        """
        batch, channels, D, H, W = volume.shape

        if axis == 'z':
            pos = position if position else torch.randint(0, D, (1,)).item()
            return volume[:, :, pos, :, :]
        elif axis == 'y':
            pos = position if position else torch.randint(0, H, (1,)).item()
            return volume[:, :, :, pos, :]
        elif axis == 'x':
            pos = position if position else torch.randint(0, W, (1,)).item()
            return volume[:, :, :, :, pos]

    @staticmethod
    def get_random_slices(volume, n_slices=3):
        """
        각 축에서 n_slices개의 랜덤 슬라이스 추출
        """
        slices = []
        for axis in ['x', 'y', 'z']:
            for _ in range(n_slices):
                slices.append(Slicer.slice_volume(volume, axis))
        return slices
```

---

## 1.3 손실 함수: WGAN-GP

SliceGAN은 Wasserstein GAN with Gradient Penalty (WGAN-GP)를 사용합니다.

### 수학적 정의

**Wasserstein Distance:**

$$W(P_r, P_g) = \sup_{\|f\|_L \leq 1} \mathbb{E}_{x \sim P_r}[f(x)] - \mathbb{E}_{x \sim P_g}[f(x)]$$

**WGAN-GP 손실 함수:**

```
L_critic = E[D(fake)] - E[D(real)] + λ * GP
L_generator = -E[D(fake)]
```

여기서 Gradient Penalty (GP):

$$GP = \mathbb{E}_{\hat{x}}[(\|\nabla_{\hat{x}} D(\hat{x})\|_2 - 1)^2]$$

### PyTorch 구현

```python
def compute_gradient_penalty(critic, real_samples, fake_samples, device):
    """
    Gradient Penalty 계산

    Args:
        critic: Critic 네트워크
        real_samples: 실제 2D 슬라이스
        fake_samples: 생성된 2D 슬라이스
        device: cuda/cpu

    Returns:
        gradient_penalty: GP 값
    """
    batch_size = real_samples.size(0)

    # 랜덤 interpolation 계수
    alpha = torch.rand(batch_size, 1, 1, 1, device=device)
    alpha = alpha.expand_as(real_samples)

    # Interpolated samples
    interpolated = alpha * real_samples + (1 - alpha) * fake_samples
    interpolated.requires_grad_(True)

    # Critic output for interpolated
    d_interpolated = critic(interpolated)

    # Gradient 계산
    gradients = torch.autograd.grad(
        outputs=d_interpolated,
        inputs=interpolated,
        grad_outputs=torch.ones_like(d_interpolated),
        create_graph=True,
        retain_graph=True
    )[0]

    # Gradient norm
    gradients = gradients.view(batch_size, -1)
    gradient_norm = gradients.norm(2, dim=1)

    # Gradient penalty
    gradient_penalty = ((gradient_norm - 1) ** 2).mean()

    return gradient_penalty


class WGANGPLoss:
    """WGAN-GP 손실 함수 클래스"""

    def __init__(self, lambda_gp=10):
        self.lambda_gp = lambda_gp

    def critic_loss(self, critic, real_slices, fake_slices, device):
        """
        Critic 손실 계산

        L = E[D(fake)] - E[D(real)] + λ * GP
        """
        real_score = critic(real_slices).mean()
        fake_score = critic(fake_slices).mean()

        gp = compute_gradient_penalty(critic, real_slices, fake_slices, device)

        loss = fake_score - real_score + self.lambda_gp * gp

        return loss, {
            'wasserstein_distance': (real_score - fake_score).item(),
            'gradient_penalty': gp.item()
        }

    def generator_loss(self, critic, fake_slices):
        """
        Generator 손실 계산

        L = -E[D(fake)]
        """
        fake_score = critic(fake_slices).mean()
        return -fake_score
```

---

## 1.4 학습 파라미터

### 권장 하이퍼파라미터

```python
# 학습 설정
TRAINING_CONFIG = {
    # 기본 설정
    'batch_size': 8,
    'n_epochs': 100,
    'latent_dim': 64,
    'image_size': 64,

    # Optimizer 설정
    'lr_generator': 0.0001,
    'lr_critic': 0.0001,
    'beta1': 0.0,
    'beta2': 0.9,

    # WGAN-GP 설정
    'lambda_gp': 10,
    'n_critic': 5,  # Generator 1회당 Critic 학습 횟수

    # 구조 설정
    'n_phases': 3,  # 배터리: 활물질, 기공, 바인더
    'ngf': 64,      # Generator feature maps
    'ndf': 64,      # Critic feature maps
}
```

### 학습 루프

```python
def train_slicegan(generator, critic, dataloader, config, device):
    """
    SliceGAN 학습 메인 루프
    """
    # Optimizers
    opt_g = torch.optim.Adam(
        generator.parameters(),
        lr=config['lr_generator'],
        betas=(config['beta1'], config['beta2'])
    )
    opt_c = torch.optim.Adam(
        critic.parameters(),
        lr=config['lr_critic'],
        betas=(config['beta1'], config['beta2'])
    )

    loss_fn = WGANGPLoss(config['lambda_gp'])
    slicer = Slicer()

    for epoch in range(config['n_epochs']):
        for i, real_images in enumerate(dataloader):
            real_images = real_images.to(device)
            batch_size = real_images.size(0)

            # ===== Critic 학습 =====
            for _ in range(config['n_critic']):
                # 랜덤 latent vector 생성
                z = torch.randn(
                    batch_size, config['latent_dim'], 4, 4, 4,
                    device=device
                )

                # 3D 볼륨 생성
                fake_volume = generator(z)

                # 랜덤 슬라이스 추출
                fake_slices = slicer.slice_volume(fake_volume, axis='z')

                # Critic 손실 계산 및 업데이트
                opt_c.zero_grad()
                c_loss, metrics = loss_fn.critic_loss(
                    critic, real_images, fake_slices.detach(), device
                )
                c_loss.backward()
                opt_c.step()

            # ===== Generator 학습 =====
            z = torch.randn(
                batch_size, config['latent_dim'], 4, 4, 4,
                device=device
            )
            fake_volume = generator(z)

            # 모든 축에서 슬라이스 추출하여 학습
            g_loss_total = 0
            for axis in ['x', 'y', 'z']:
                fake_slices = slicer.slice_volume(fake_volume, axis=axis)
                g_loss_total += loss_fn.generator_loss(critic, fake_slices)

            opt_g.zero_grad()
            g_loss_total.backward()
            opt_g.step()

            # 로깅
            if i % 100 == 0:
                print(f"Epoch [{epoch}/{config['n_epochs']}] "
                      f"Step [{i}] "
                      f"D_loss: {c_loss.item():.4f} "
                      f"G_loss: {g_loss_total.item():.4f} "
                      f"W_dist: {metrics['wasserstein_distance']:.4f}")

    return generator, critic
```

---

## 1.5 배터리 전극 적용 시 고려사항

### 1.5.1 다상 구조 처리

배터리 전극은 여러 상(phase)으로 구성됩니다:

```python
# 배터리 전극 상(phase) 정의
ELECTRODE_PHASES = {
    0: 'Active Material (활물질)',      # NMC, LFP 등
    1: 'Pore (기공)',                   # 전해질이 채워지는 공간
    2: 'Binder/CBD (바인더/전도성첨가제)', # PVDF, Carbon Black
}

# One-hot 인코딩 예시
def phase_to_onehot(phase_map, n_phases=3):
    """
    정수 레이블을 one-hot 인코딩으로 변환

    Args:
        phase_map: (H, W) 형태의 정수 레이블
        n_phases: 상의 개수

    Returns:
        (n_phases, H, W) 형태의 one-hot 텐서
    """
    H, W = phase_map.shape
    onehot = torch.zeros(n_phases, H, W)
    for i in range(n_phases):
        onehot[i] = (phase_map == i).float()
    return onehot
```

### 1.5.2 구조적 특성 평가

```python
def evaluate_microstructure(volume, voxel_size=0.1):
    """
    생성된 미세구조의 품질 평가

    Args:
        volume: (n_phases, D, H, W) 형태의 3D 볼륨
        voxel_size: 복셀 크기 (μm)

    Returns:
        metrics: 구조적 특성 딕셔너리
    """
    # Argmax로 단일 레이블 변환
    labels = volume.argmax(dim=0)

    metrics = {}

    # 1. Volume Fraction (체적 분율)
    total_voxels = labels.numel()
    for phase_id, phase_name in ELECTRODE_PHASES.items():
        phase_voxels = (labels == phase_id).sum().item()
        metrics[f'volume_fraction_{phase_name}'] = phase_voxels / total_voxels

    # 2. Porosity (기공률)
    metrics['porosity'] = metrics['volume_fraction_Pore (기공)']

    # 3. Specific Surface Area (비표면적) - 근사 계산
    # 인접 복셀 간 상 경계 카운팅
    surface_voxels = 0
    for axis in range(3):
        diff = torch.diff(labels, dim=axis)
        surface_voxels += (diff != 0).sum().item()

    # 표면적 = 경계 복셀 수 × 복셀 면적
    surface_area = surface_voxels * (voxel_size ** 2)
    total_volume = total_voxels * (voxel_size ** 3)
    metrics['specific_surface_area'] = surface_area / total_volume  # μm²/μm³

    return metrics
```

### 1.5.3 연속성 보장

전극 성능을 위해 활물질과 기공의 연속성이 중요합니다:

```python
from scipy import ndimage

def check_percolation(volume, phase_id, direction='z'):
    """
    특정 상의 관통(percolation) 여부 확인

    Args:
        volume: 3D 볼륨 (D, H, W)
        phase_id: 확인할 상의 ID
        direction: 관통 방향 ('x', 'y', 'z')

    Returns:
        percolates: 관통 여부 (bool)
    """
    # 해당 상만 추출
    binary = (volume == phase_id).numpy()

    # Connected component labeling
    labeled, num_features = ndimage.label(binary)

    # 방향에 따른 시작/끝 면 확인
    if direction == 'z':
        start_labels = set(labeled[0, :, :].flatten()) - {0}
        end_labels = set(labeled[-1, :, :].flatten()) - {0}
    elif direction == 'y':
        start_labels = set(labeled[:, 0, :].flatten()) - {0}
        end_labels = set(labeled[:, -1, :].flatten()) - {0}
    else:  # x
        start_labels = set(labeled[:, :, 0].flatten()) - {0}
        end_labels = set(labeled[:, :, -1].flatten()) - {0}

    # 시작면과 끝면에 동일한 레이블이 있으면 관통
    percolates = bool(start_labels & end_labels)

    return percolates
```

---

## 1.6 참고 자료

### 논문 및 원본 구현

| 자료 | 링크 | 설명 |
|------|------|------|
| SliceGAN 원본 | [GitHub](https://github.com/stke9/SliceGAN) | 공식 구현체 |
| CMRL-JHU Fork | [GitHub](https://github.com/CMRL-JHU/sliceGAN) | Johns Hopkins 확장 버전 |
| MicroLib 논문 | [Nature](https://www.nature.com/articles/s41597-022-01744-1) | 배터리 미세구조 라이브러리 |

### 추가 학습 자료

1. **WGAN-GP 원논문**: "Improved Training of Wasserstein GANs" (Gulrajani et al., 2017)
2. **3D CNN 튜토리얼**: PyTorch 공식 문서의 3D Convolution 가이드
3. **배터리 미세구조 분석**: NREL Battery Microstructure Library 문서

---

# Part 2: 프로젝트 초기 구조 설계

## 2.1 개요

체계적인 프로젝트 구조는 코드 유지보수, 협업, 재현성을 위해 필수적입니다. 본 섹션에서는 배터리 전극 미세구조 생성기 프로젝트의 권장 폴더 구조와 설정 파일을 다룹니다.

---

## 2.2 폴더 구조

```
전극_구조_자동생성기/
│
├── configs/                    # 설정 파일
│   ├── config.yaml            # 메인 설정
│   ├── model/                 # 모델별 설정
│   │   ├── slicegan.yaml
│   │   └── segmentation.yaml
│   └── experiment/            # 실험 설정
│       └── default.yaml
│
├── data/
│   ├── raw/                   # 원본 SEM/FIB-SEM 이미지
│   │   ├── cathode/
│   │   └── anode/
│   ├── processed/             # 전처리 완료 데이터
│   │   ├── segmented/
│   │   └── normalized/
│   ├── generated/             # 생성된 3D 구조
│   │   ├── voxel/
│   │   └── mesh/
│   └── external/              # 외부 데이터셋 (NREL 등)
│
├── models/
│   ├── slicegan/              # SliceGAN 구현
│   │   ├── __init__.py
│   │   ├── generator.py
│   │   ├── critic.py
│   │   └── trainer.py
│   ├── segmentation/          # 분할 모델
│   │   ├── __init__.py
│   │   ├── unet3d.py
│   │   └── swin_unetr.py
│   └── checkpoints/           # 학습된 모델 가중치
│       ├── slicegan/
│       └── segmentation/
│
├── preprocessing/             # 이미지 전처리 모듈
│   ├── __init__.py
│   ├── loader.py              # 데이터 로딩
│   ├── filters.py             # 노이즈 제거, 필터링
│   ├── augmentation.py        # 데이터 증강
│   └── normalization.py       # 정규화
│
├── postprocessing/            # 후처리 모듈
│   ├── __init__.py
│   ├── voxel_to_mesh.py       # Marching Cubes
│   ├── mesh_refinement.py     # 메시 정제
│   └── comsol_export.py       # COMSOL 내보내기
│
├── utils/                     # 유틸리티 함수
│   ├── __init__.py
│   ├── io.py                  # 입출력
│   ├── visualization.py       # 시각화
│   ├── metrics.py             # 평가 메트릭
│   └── logging.py             # 로깅
│
├── experiments/               # 실험 결과
│   ├── logs/                  # TensorBoard 로그
│   ├── results/               # 실험 결과
│   └── figures/               # 생성 그래프/이미지
│
├── notebooks/                 # Jupyter 노트북
│   ├── 01_data_exploration.ipynb
│   ├── 02_model_training.ipynb
│   └── 03_result_analysis.ipynb
│
├── tests/                     # 테스트 코드
│   ├── test_models.py
│   ├── test_preprocessing.py
│   └── test_postprocessing.py
│
├── scripts/                   # 실행 스크립트
│   ├── train.py
│   ├── generate.py
│   └── export_comsol.py
│
├── docs/                      # 문서
│   ├── api/
│   └── tutorials/
│
├── requirements.txt           # Python 의존성
├── setup.py                   # 패키지 설정
├── Dockerfile                 # Docker 설정
├── .gitignore
└── README.md
```

### 폴더 역할 설명

| 폴더 | 역할 | 주요 파일 |
|------|------|----------|
| `configs/` | YAML 설정 파일 | 하이퍼파라미터, 경로 등 |
| `data/` | 모든 데이터 저장 | raw → processed → generated |
| `models/` | 딥러닝 모델 정의 | SliceGAN, U-Net 등 |
| `preprocessing/` | 입력 데이터 처리 | 필터, 증강, 정규화 |
| `postprocessing/` | 출력 데이터 처리 | 메시 변환, COMSOL 연계 |
| `utils/` | 공통 유틸리티 | I/O, 시각화, 메트릭 |
| `experiments/` | 실험 로그/결과 | TensorBoard, 체크포인트 |

---

## 2.3 설정 파일 예시

### 2.3.1 메인 설정 (config.yaml)

```yaml
# config.yaml
# 전극 구조 자동생성기 메인 설정 파일

# ============================================================
# 프로젝트 기본 정보
# ============================================================
project:
  name: "electrode_structure_generator"
  version: "1.0.0"
  description: "배터리 전극 미세구조 자동 생성 시스템"

# ============================================================
# 경로 설정
# ============================================================
paths:
  data_root: "./data"
  raw_data: "${paths.data_root}/raw"
  processed_data: "${paths.data_root}/processed"
  generated_data: "${paths.data_root}/generated"
  checkpoints: "./models/checkpoints"
  logs: "./experiments/logs"
  results: "./experiments/results"

# ============================================================
# 데이터 설정
# ============================================================
data:
  # 이미지 크기
  image_size: 64

  # 전극 상(phase) 정의
  phases:
    - name: "active_material"
      label: 0
      color: [255, 0, 0]      # 빨강
    - name: "pore"
      label: 1
      color: [0, 255, 0]      # 초록
    - name: "binder_cbd"
      label: 2
      color: [0, 0, 255]      # 파랑

  n_phases: 3

  # 데이터 증강
  augmentation:
    enabled: true
    horizontal_flip: true
    vertical_flip: true
    rotation_90: true
    random_crop: false

# ============================================================
# 모델 설정
# ============================================================
model:
  # SliceGAN 설정
  slicegan:
    latent_dim: 64
    ngf: 64                   # Generator feature maps
    ndf: 64                   # Critic feature maps
    output_size: 64           # 64x64x64 voxel

  # Segmentation 모델 (선택)
  segmentation:
    architecture: "unet3d"    # unet3d, swin_unetr
    encoder_depth: 4
    initial_features: 32

# ============================================================
# 학습 설정
# ============================================================
training:
  # 기본 설정
  batch_size: 8
  n_epochs: 100
  num_workers: 4

  # Optimizer
  optimizer:
    type: "adam"
    lr_generator: 0.0001
    lr_critic: 0.0001
    beta1: 0.0
    beta2: 0.9
    weight_decay: 0.0

  # WGAN-GP 설정
  wgan_gp:
    lambda_gp: 10
    n_critic: 5               # Generator 1회당 Critic 학습 횟수

  # 체크포인트
  checkpoint:
    save_every: 10            # epochs
    keep_last_n: 5

  # Early stopping
  early_stopping:
    enabled: true
    patience: 20
    min_delta: 0.001

# ============================================================
# 추론/생성 설정
# ============================================================
generation:
  n_samples: 10               # 생성할 샘플 수
  output_format: "npy"        # npy, vtk, stl
  seed: 42                    # 재현성을 위한 시드

# ============================================================
# 후처리 설정
# ============================================================
postprocessing:
  # Marching Cubes
  marching_cubes:
    level: 0.5
    spacing: [1.0, 1.0, 1.0]

  # 메시 정제
  mesh_refinement:
    smooth_iterations: 10
    decimate_ratio: 0.5

  # COMSOL 내보내기
  comsol:
    format: "stl"             # stl, nas, mphtxt
    units: "um"               # um, mm, m

# ============================================================
# 로깅 설정
# ============================================================
logging:
  level: "INFO"               # DEBUG, INFO, WARNING, ERROR
  tensorboard: true
  wandb:
    enabled: false
    project: "electrode_generator"
    entity: null

# ============================================================
# 하드웨어 설정
# ============================================================
hardware:
  device: "cuda"              # cuda, cpu
  gpu_ids: [0]
  mixed_precision: true       # FP16 학습
```

### 2.3.2 SliceGAN 모델 설정 (model/slicegan.yaml)

```yaml
# models/slicegan.yaml
# SliceGAN 특화 설정

defaults:
  - _self_

model:
  name: "SliceGAN"

  generator:
    type: "3d_transpose_conv"
    layers:
      - {out_channels: 512, kernel: 4, stride: 2, padding: 1}
      - {out_channels: 256, kernel: 4, stride: 2, padding: 1}
      - {out_channels: 128, kernel: 4, stride: 2, padding: 1}
      - {out_channels: 64, kernel: 4, stride: 2, padding: 1}
      - {out_channels: "${data.n_phases}", kernel: 3, stride: 1, padding: 1}
    activation: "relu"
    output_activation: "softmax"
    batch_norm: true

  critic:
    type: "2d_conv"
    layers:
      - {out_channels: 64, kernel: 4, stride: 2, padding: 1}
      - {out_channels: 128, kernel: 4, stride: 2, padding: 1}
      - {out_channels: 256, kernel: 4, stride: 2, padding: 1}
      - {out_channels: 512, kernel: 4, stride: 2, padding: 1}
      - {out_channels: 1, kernel: 4, stride: 1, padding: 0}
    activation: "leaky_relu"
    leaky_slope: 0.2
    layer_norm: true

  slicer:
    axes: ["x", "y", "z"]
    random_position: true
```

---

## 2.4 requirements.txt

```txt
# requirements.txt
# 전극 구조 자동생성기 Python 의존성

# ============================================================
# 핵심 딥러닝 프레임워크
# ============================================================
torch>=2.0.0
torchvision>=0.15.0
torchaudio>=2.0.0

# ============================================================
# 이미지 처리 및 과학 계산
# ============================================================
numpy>=1.24.0
scipy>=1.10.0
scikit-image>=0.21.0
opencv-python>=4.8.0
Pillow>=10.0.0

# ============================================================
# 3D 메시 처리
# ============================================================
trimesh>=3.23.0
pyvista>=0.42.0
vtk>=9.2.0
meshio>=5.3.0

# ============================================================
# 데이터 처리 및 시각화
# ============================================================
pandas>=2.0.0
matplotlib>=3.7.0
seaborn>=0.12.0
plotly>=5.15.0

# ============================================================
# 설정 및 실험 관리
# ============================================================
hydra-core>=1.3.0
omegaconf>=2.3.0
pyyaml>=6.0
python-dotenv>=1.0.0

# ============================================================
# 로깅 및 모니터링
# ============================================================
tensorboard>=2.14.0
wandb>=0.15.0
tqdm>=4.65.0

# ============================================================
# Jupyter 노트북
# ============================================================
jupyter>=1.0.0
jupyterlab>=4.0.0
ipywidgets>=8.0.0

# ============================================================
# 테스트
# ============================================================
pytest>=7.4.0
pytest-cov>=4.1.0

# ============================================================
# 코드 품질
# ============================================================
black>=23.7.0
isort>=5.12.0
flake8>=6.1.0
mypy>=1.4.0

# ============================================================
# COMSOL/Blender 연계 (선택)
# ============================================================
# mph>=1.2.0           # COMSOL Python API (설치 후 주석 해제)
# bpy                  # Blender Python (Blender 내장 또는 별도 설치)

# ============================================================
# GPU 가속 (선택)
# ============================================================
# cupy-cuda12x>=12.0.0  # CUDA 12.x용
```

---

## 2.5 Docker 환경 설정

### 2.5.1 Dockerfile

```dockerfile
# Dockerfile
# 전극 구조 자동생성기 Docker 이미지

# ============================================================
# 베이스 이미지: PyTorch with CUDA
# ============================================================
FROM pytorch/pytorch:2.1.0-cuda12.1-cudnn8-runtime

# 환경 변수 설정
ENV DEBIAN_FRONTEND=noninteractive
ENV PYTHONUNBUFFERED=1
ENV PYTHONDONTWRITEBYTECODE=1

# 작업 디렉토리 설정
WORKDIR /app

# ============================================================
# 시스템 패키지 설치
# ============================================================
RUN apt-get update && apt-get install -y --no-install-recommends \
    git \
    wget \
    curl \
    vim \
    libgl1-mesa-glx \
    libglib2.0-0 \
    libsm6 \
    libxext6 \
    libxrender-dev \
    libgomp1 \
    && rm -rf /var/lib/apt/lists/*

# ============================================================
# Python 의존성 설치
# ============================================================
COPY requirements.txt .
RUN pip install --no-cache-dir --upgrade pip && \
    pip install --no-cache-dir -r requirements.txt

# ============================================================
# 프로젝트 파일 복사
# ============================================================
COPY . .

# ============================================================
# 포트 설정 (TensorBoard, Jupyter)
# ============================================================
EXPOSE 6006 8888

# ============================================================
# 엔트리포인트
# ============================================================
CMD ["python", "scripts/train.py"]
```

### 2.5.2 docker-compose.yaml

```yaml
# docker-compose.yaml
version: '3.8'

services:
  # 학습 서비스
  trainer:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: electrode_trainer
    runtime: nvidia
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
    volumes:
      - ./data:/app/data
      - ./models/checkpoints:/app/models/checkpoints
      - ./experiments:/app/experiments
    command: python scripts/train.py

  # TensorBoard 서비스
  tensorboard:
    image: tensorflow/tensorflow:latest
    container_name: electrode_tensorboard
    ports:
      - "6006:6006"
    volumes:
      - ./experiments/logs:/logs
    command: tensorboard --logdir=/logs --bind_all

  # Jupyter Lab 서비스
  jupyter:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: electrode_jupyter
    runtime: nvidia
    ports:
      - "8888:8888"
    volumes:
      - .:/app
    command: jupyter lab --ip=0.0.0.0 --allow-root --no-browser
```

---

## 2.6 프로젝트 초기화 스크립트

```python
#!/usr/bin/env python
# scripts/init_project.py
"""
프로젝트 폴더 구조 초기화 스크립트
"""

import os
from pathlib import Path

# 프로젝트 루트 디렉토리
PROJECT_ROOT = Path(__file__).parent.parent

# 생성할 폴더 구조
DIRECTORIES = [
    "configs/model",
    "configs/experiment",
    "data/raw/cathode",
    "data/raw/anode",
    "data/processed/segmented",
    "data/processed/normalized",
    "data/generated/voxel",
    "data/generated/mesh",
    "data/external",
    "models/slicegan",
    "models/segmentation",
    "models/checkpoints/slicegan",
    "models/checkpoints/segmentation",
    "preprocessing",
    "postprocessing",
    "utils",
    "experiments/logs",
    "experiments/results",
    "experiments/figures",
    "notebooks",
    "tests",
    "scripts",
    "docs/api",
    "docs/tutorials",
]

# 생성할 __init__.py 파일이 필요한 폴더
PYTHON_PACKAGES = [
    "models",
    "models/slicegan",
    "models/segmentation",
    "preprocessing",
    "postprocessing",
    "utils",
]


def create_directories():
    """폴더 구조 생성"""
    for dir_path in DIRECTORIES:
        full_path = PROJECT_ROOT / dir_path
        full_path.mkdir(parents=True, exist_ok=True)
        print(f"Created: {full_path}")


def create_init_files():
    """__init__.py 파일 생성"""
    for pkg_path in PYTHON_PACKAGES:
        init_file = PROJECT_ROOT / pkg_path / "__init__.py"
        if not init_file.exists():
            init_file.touch()
            print(f"Created: {init_file}")


def create_gitkeep_files():
    """빈 폴더용 .gitkeep 파일 생성"""
    for dir_path in DIRECTORIES:
        full_path = PROJECT_ROOT / dir_path
        gitkeep = full_path / ".gitkeep"
        if not any(full_path.iterdir()):
            gitkeep.touch()
            print(f"Created: {gitkeep}")


def create_gitignore():
    """기본 .gitignore 파일 생성"""
    gitignore_content = """
# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
env/
venv/
.venv/

# PyTorch
*.pt
*.pth
*.onnx

# Data
data/raw/
data/processed/
data/generated/
data/external/
*.npy
*.npz
*.h5
*.hdf5

# Model checkpoints
models/checkpoints/

# Experiments
experiments/logs/
experiments/results/
*.log

# Jupyter
.ipynb_checkpoints/
*.ipynb_checkpoints

# IDE
.idea/
.vscode/
*.swp
*.swo

# OS
.DS_Store
Thumbs.db

# Environment
.env
.env.local

# Build
build/
dist/
*.egg-info/
"""
    gitignore_path = PROJECT_ROOT / ".gitignore"
    if not gitignore_path.exists():
        gitignore_path.write_text(gitignore_content.strip())
        print(f"Created: {gitignore_path}")


def main():
    """메인 실행 함수"""
    print("=" * 50)
    print("프로젝트 구조 초기화 시작")
    print("=" * 50)

    create_directories()
    create_init_files()
    create_gitkeep_files()
    create_gitignore()

    print("=" * 50)
    print("프로젝트 구조 초기화 완료!")
    print("=" * 50)


if __name__ == "__main__":
    main()
```

---

## 2.7 참고 자료

### 프로젝트 구조 관련

| 자료 | 링크 | 설명 |
|------|------|------|
| AI Summer 가이드 | [Link](https://theaisummer.com/best-practices-deep-learning-code/) | 딥러닝 코드 베스트 프랙티스 |
| MLOps 구조화 | [Link](https://towardsdatascience.com/structuring-your-machine-learning-project-with-mlops-in-mind-41a8d65987c9/) | MLOps 관점의 프로젝트 구조 |
| Hydra 공식 문서 | [Link](https://hydra.cc/docs/intro/) | 설정 관리 프레임워크 |

### 추가 도구

1. **Cookiecutter Data Science**: 데이터 과학 프로젝트 템플릿 생성 도구
2. **DVC (Data Version Control)**: 데이터 버전 관리 도구
3. **MLflow**: 실험 추적 및 모델 관리 플랫폼

---

# Part 3: 데이터 수집/전처리 파이프라인 설계

## 3.1 개요

배터리 전극 미세구조 생성의 품질은 학습 데이터의 품질에 직접적으로 의존합니다. 본 섹션에서는 데이터 소스, 이미지 분할(segmentation), 전처리 파이프라인, 그리고 품질 평가 메트릭을 다룹니다.

---

## 3.2 데이터 소스

### 3.2.1 오픈소스 데이터셋

#### NREL Battery Microstructure Library

NREL(National Renewable Energy Laboratory)에서 제공하는 배터리 미세구조 데이터셋입니다.

```python
"""
NREL Battery Microstructure Library 다운로드 및 로딩
https://www.nrel.gov/transportation/battery-microstructure-library-data
"""

import requests
import zipfile
from pathlib import Path


class NRELDataLoader:
    """NREL 배터리 미세구조 데이터 로더"""

    BASE_URL = "https://data.nrel.gov/submissions/"

    # 사용 가능한 데이터셋 목록
    DATASETS = {
        "nmc_cathode": {
            "id": "123",
            "description": "NMC 양극 FIB-SEM 데이터",
            "resolution": "10nm",
            "size": "500x500x500"
        },
        "graphite_anode": {
            "id": "124",
            "description": "흑연 음극 X-ray CT 데이터",
            "resolution": "500nm",
            "size": "1000x1000x1000"
        },
    }

    def __init__(self, data_dir: str = "./data/external"):
        self.data_dir = Path(data_dir)
        self.data_dir.mkdir(parents=True, exist_ok=True)

    def download_dataset(self, dataset_name: str):
        """데이터셋 다운로드"""
        if dataset_name not in self.DATASETS:
            raise ValueError(f"Unknown dataset: {dataset_name}")

        # 실제 다운로드 로직
        dataset_info = self.DATASETS[dataset_name]
        print(f"Downloading {dataset_name}...")
        print(f"  Description: {dataset_info['description']}")
        print(f"  Resolution: {dataset_info['resolution']}")

        # 다운로드 경로
        save_path = self.data_dir / f"{dataset_name}.zip"

        # 실제 구현에서는 requests로 다운로드
        # response = requests.get(url, stream=True)
        # with open(save_path, 'wb') as f:
        #     for chunk in response.iter_content(chunk_size=8192):
        #         f.write(chunk)

        return save_path

    def list_available_datasets(self):
        """사용 가능한 데이터셋 목록 출력"""
        print("Available NREL Battery Microstructure Datasets:")
        print("-" * 50)
        for name, info in self.DATASETS.items():
            print(f"  {name}:")
            print(f"    - {info['description']}")
            print(f"    - Resolution: {info['resolution']}")
            print(f"    - Size: {info['size']}")
```

### 3.2.2 FIB-SEM 데이터 수집 가이드

FIB-SEM(Focused Ion Beam - Scanning Electron Microscopy) 데이터 수집 시 고려사항:

| 파라미터 | 권장 값 | 설명 |
|----------|---------|------|
| 해상도 | 10-50 nm/pixel | 활물질 입자 크기에 따라 조정 |
| 슬라이스 간격 | 10-50 nm | 해상도와 동일하게 유지 |
| 이미지 크기 | 1024×1024 이상 | 통계적 대표성 확보 |
| 슬라이스 수 | 200개 이상 | 3D 재구성에 충분한 깊이 |
| 대비 | 각 상이 구분되도록 | 분할 정확도에 직접 영향 |

```python
# FIB-SEM 데이터 품질 체크리스트
FIB_SEM_CHECKLIST = {
    "contrast": {
        "description": "상(phase) 간 대비가 충분한가?",
        "check": "히스토그램에서 피크가 구분되어야 함"
    },
    "alignment": {
        "description": "슬라이스 간 정렬이 되어 있는가?",
        "check": "pyStackReg 등으로 정렬 필요할 수 있음"
    },
    "artifacts": {
        "description": "커튼 효과 등 아티팩트가 있는가?",
        "check": "필터링으로 제거 또는 해당 영역 제외"
    },
    "sampling": {
        "description": "대표적인 영역을 촬영했는가?",
        "check": "여러 위치에서 샘플링 권장"
    }
}
```

---

## 3.3 이미지 분할 (Segmentation)

### 3.3.1 3D U-Net 아키텍처

3D U-Net은 의료 영상 분할에서 널리 사용되며, 배터리 미세구조 분할에도 효과적입니다.

```
┌───────────────────────────────────────────────────────────────────┐
│                        3D U-Net 아키텍처                           │
├───────────────────────────────────────────────────────────────────┤
│                                                                   │
│  Input                                                   Output   │
│  (64³×1)                                               (64³×3)   │
│     │                                                      ▲      │
│     ▼                                                      │      │
│  ┌──────┐     ┌──────┐     ┌──────┐     ┌──────┐     ┌──────┐   │
│  │Conv3D│────►│Conv3D│────►│Conv3D│────►│Conv3D│────►│Conv3D│   │
│  │  32  │     │  64  │     │ 128  │     │ 256  │     │ 512  │   │
│  └──┬───┘     └──┬───┘     └──┬───┘     └──┬───┘     └──┬───┘   │
│     │            │            │            │            │        │
│     │  ┌─────────┼────────────┼────────────┼────────────┘        │
│     │  │         │            │            │                     │
│     │  │  ┌──────┼────────────┼────────────┘                     │
│     │  │  │      │            │                                  │
│     │  │  │  ┌───┼────────────┘                                  │
│     │  │  │  │   │                                               │
│     ▼  ▼  ▼  ▼   ▼                                               │
│  ┌──────┐  ┌──────┐  ┌──────┐  ┌──────┐  ┌──────┐               │
│  │UpConv│◄─│UpConv│◄─│UpConv│◄─│UpConv│◄─│BottleNeck           │
│  │  32  │  │  64  │  │ 128  │  │ 256  │  │ 512  │               │
│  └──────┘  └──────┘  └──────┘  └──────┘  └──────┘               │
│                                                                   │
│  Skip Connections: 인코더 특징을 디코더에 전달                       │
│                                                                   │
└───────────────────────────────────────────────────────────────────┘
```

**PyTorch 구현:**

```python
import torch
import torch.nn as nn


class DoubleConv3D(nn.Module):
    """3D U-Net의 기본 블록: Conv3D → BN → ReLU × 2"""

    def __init__(self, in_channels, out_channels):
        super().__init__()
        self.double_conv = nn.Sequential(
            nn.Conv3d(in_channels, out_channels, kernel_size=3, padding=1),
            nn.BatchNorm3d(out_channels),
            nn.ReLU(inplace=True),
            nn.Conv3d(out_channels, out_channels, kernel_size=3, padding=1),
            nn.BatchNorm3d(out_channels),
            nn.ReLU(inplace=True)
        )

    def forward(self, x):
        return self.double_conv(x)


class UNet3D(nn.Module):
    """
    3D U-Net for Battery Electrode Segmentation

    입력: (batch, 1, D, H, W) - 그레이스케일 3D 볼륨
    출력: (batch, n_classes, D, H, W) - 분할 마스크
    """

    def __init__(self, in_channels=1, n_classes=3, features=[32, 64, 128, 256]):
        super().__init__()

        self.downs = nn.ModuleList()
        self.ups = nn.ModuleList()
        self.pool = nn.MaxPool3d(kernel_size=2, stride=2)

        # Encoder (다운샘플링)
        for feature in features:
            self.downs.append(DoubleConv3D(in_channels, feature))
            in_channels = feature

        # Bottleneck
        self.bottleneck = DoubleConv3D(features[-1], features[-1] * 2)

        # Decoder (업샘플링)
        for feature in reversed(features):
            self.ups.append(
                nn.ConvTranspose3d(feature * 2, feature, kernel_size=2, stride=2)
            )
            self.ups.append(DoubleConv3D(feature * 2, feature))

        # 최종 출력 레이어
        self.final_conv = nn.Conv3d(features[0], n_classes, kernel_size=1)

    def forward(self, x):
        skip_connections = []

        # Encoder
        for down in self.downs:
            x = down(x)
            skip_connections.append(x)
            x = self.pool(x)

        x = self.bottleneck(x)
        skip_connections = skip_connections[::-1]

        # Decoder
        for idx in range(0, len(self.ups), 2):
            x = self.ups[idx](x)  # Upsample
            skip = skip_connections[idx // 2]

            # 크기 불일치 처리
            if x.shape != skip.shape:
                x = nn.functional.interpolate(x, size=skip.shape[2:])

            x = torch.cat((skip, x), dim=1)  # Skip connection
            x = self.ups[idx + 1](x)  # DoubleConv

        return self.final_conv(x)
```

### 3.3.2 Swin Transformer 기반 분할 (최신)

Swin UNETR은 Transformer 기반의 최신 분할 모델입니다.

```python
# MONAI 라이브러리 사용 (의료 영상 전용)
# pip install monai

from monai.networks.nets import SwinUNETR


def create_swin_unetr(n_classes=3, img_size=64):
    """
    Swin UNETR 모델 생성

    Swin Transformer + U-Net 구조
    - 장점: 전역 컨텍스트 포착, 긴 범위 의존성 모델링
    - 단점: 계산 비용 높음, 대규모 데이터 필요
    """
    model = SwinUNETR(
        img_size=(img_size, img_size, img_size),
        in_channels=1,
        out_channels=n_classes,
        feature_size=48,
        use_checkpoint=True,  # 메모리 효율성
    )
    return model


# 분할 모델 선택 가이드
SEGMENTATION_MODELS = {
    "3d_unet": {
        "model": UNet3D,
        "pros": ["빠른 학습", "적은 데이터로 가능", "해석 용이"],
        "cons": ["지역적 특징만 포착", "큰 구조 놓칠 수 있음"],
        "recommended_for": "소규모 데이터셋, 빠른 프로토타이핑"
    },
    "swin_unetr": {
        "model": "SwinUNETR",
        "pros": ["전역 컨텍스트", "SOTA 성능", "전이 학습 가능"],
        "cons": ["많은 데이터 필요", "긴 학습 시간", "메모리 사용량"],
        "recommended_for": "대규모 데이터셋, 높은 정확도 필요 시"
    }
}
```

### 3.3.3 분할 학습 파이프라인

```python
import torch
from torch.utils.data import DataLoader
import torch.nn.functional as F


def train_segmentation_model(model, train_loader, val_loader, config):
    """
    분할 모델 학습

    Args:
        model: 분할 모델 (UNet3D 또는 SwinUNETR)
        train_loader: 학습 데이터 로더
        val_loader: 검증 데이터 로더
        config: 학습 설정
    """
    device = torch.device(config['device'])
    model = model.to(device)

    # 손실 함수: Dice Loss + Cross Entropy (혼합)
    def combined_loss(pred, target):
        # Cross Entropy
        ce_loss = F.cross_entropy(pred, target)

        # Dice Loss
        pred_soft = F.softmax(pred, dim=1)
        dice_loss = 0
        for c in range(pred.shape[1]):
            pred_c = pred_soft[:, c]
            target_c = (target == c).float()
            intersection = (pred_c * target_c).sum()
            dice_loss += 1 - (2 * intersection + 1) / (pred_c.sum() + target_c.sum() + 1)
        dice_loss /= pred.shape[1]

        return 0.5 * ce_loss + 0.5 * dice_loss

    optimizer = torch.optim.AdamW(
        model.parameters(),
        lr=config['learning_rate'],
        weight_decay=config['weight_decay']
    )

    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(
        optimizer, T_max=config['n_epochs']
    )

    best_dice = 0
    for epoch in range(config['n_epochs']):
        # 학습
        model.train()
        train_loss = 0
        for batch in train_loader:
            images = batch['image'].to(device)
            labels = batch['label'].to(device)

            optimizer.zero_grad()
            outputs = model(images)
            loss = combined_loss(outputs, labels)
            loss.backward()
            optimizer.step()

            train_loss += loss.item()

        # 검증
        model.eval()
        val_dice = evaluate_dice(model, val_loader, device)

        scheduler.step()

        print(f"Epoch {epoch+1}/{config['n_epochs']}")
        print(f"  Train Loss: {train_loss/len(train_loader):.4f}")
        print(f"  Val Dice: {val_dice:.4f}")

        # 최고 모델 저장
        if val_dice > best_dice:
            best_dice = val_dice
            torch.save(model.state_dict(), config['best_model_path'])

    return model


def evaluate_dice(model, dataloader, device):
    """Dice 계수 계산"""
    model.eval()
    total_dice = 0
    n_samples = 0

    with torch.no_grad():
        for batch in dataloader:
            images = batch['image'].to(device)
            labels = batch['label'].to(device)

            outputs = model(images)
            preds = outputs.argmax(dim=1)

            # 각 클래스별 Dice 계산 후 평균
            for c in range(outputs.shape[1]):
                pred_c = (preds == c).float()
                label_c = (labels == c).float()
                intersection = (pred_c * label_c).sum()
                dice = (2 * intersection) / (pred_c.sum() + label_c.sum() + 1e-8)
                total_dice += dice.item()

            n_samples += 1

    return total_dice / (n_samples * outputs.shape[1])
```

---

## 3.4 전처리 파이프라인

### 3.4.1 이미지 로딩

```python
import numpy as np
from pathlib import Path
from skimage import io
import tifffile


class ImageLoader:
    """다양한 포맷의 이미지 로딩 지원"""

    SUPPORTED_FORMATS = ['.tif', '.tiff', '.png', '.jpg', '.npy', '.npz']

    @staticmethod
    def load_image(path: str) -> np.ndarray:
        """
        이미지 파일 로딩

        지원 포맷:
        - TIFF (단일/스택): FIB-SEM 표준 포맷
        - PNG/JPG: 2D 이미지
        - NPY/NPZ: NumPy 배열
        """
        path = Path(path)
        suffix = path.suffix.lower()

        if suffix in ['.tif', '.tiff']:
            # TIFF 스택 (3D) 지원
            return tifffile.imread(str(path))
        elif suffix in ['.png', '.jpg', '.jpeg']:
            return io.imread(str(path))
        elif suffix == '.npy':
            return np.load(str(path))
        elif suffix == '.npz':
            data = np.load(str(path))
            return data[list(data.keys())[0]]
        else:
            raise ValueError(f"Unsupported format: {suffix}")

    @staticmethod
    def load_image_stack(directory: str, pattern: str = "*.tif") -> np.ndarray:
        """
        폴더 내 이미지 시퀀스를 3D 스택으로 로딩

        Args:
            directory: 이미지 폴더 경로
            pattern: 파일 패턴 (glob)

        Returns:
            3D numpy 배열 (D, H, W)
        """
        directory = Path(directory)
        files = sorted(directory.glob(pattern))

        if not files:
            raise FileNotFoundError(f"No files matching {pattern} in {directory}")

        # 첫 이미지로 크기 확인
        first_img = io.imread(files[0])
        stack = np.zeros((len(files), *first_img.shape), dtype=first_img.dtype)

        for i, f in enumerate(files):
            stack[i] = io.imread(f)

        return stack
```

### 3.4.2 노이즈 제거 및 필터링

```python
import numpy as np
from scipy import ndimage
from skimage import filters, restoration
from skimage.morphology import ball


class NoiseFilters:
    """FIB-SEM 이미지 노이즈 제거 필터"""

    @staticmethod
    def median_filter_3d(volume: np.ndarray, size: int = 3) -> np.ndarray:
        """
        3D 중앙값 필터

        - 점 노이즈(salt-and-pepper) 제거에 효과적
        - 에지 보존
        """
        return ndimage.median_filter(volume, size=size)

    @staticmethod
    def gaussian_filter_3d(volume: np.ndarray, sigma: float = 1.0) -> np.ndarray:
        """
        3D 가우시안 필터

        - 전반적인 노이즈 감소
        - 에지가 약간 흐려질 수 있음
        """
        return ndimage.gaussian_filter(volume, sigma=sigma)

    @staticmethod
    def non_local_means_3d(volume: np.ndarray, h: float = 0.1) -> np.ndarray:
        """
        Non-Local Means 필터

        - 텍스처 보존하면서 노이즈 제거
        - 계산 비용 높음
        """
        return restoration.denoise_nl_means(
            volume,
            h=h,
            fast_mode=True,
            patch_size=5,
            patch_distance=6
        )

    @staticmethod
    def bilateral_filter_3d(volume: np.ndarray,
                            sigma_spatial: float = 3,
                            sigma_intensity: float = 0.1) -> np.ndarray:
        """
        양방향 필터 (슬라이스별 적용)

        - 에지 보존 스무딩
        - 3D에서는 슬라이스별 적용 후 z축 스무딩
        """
        filtered = np.zeros_like(volume, dtype=np.float64)

        for i in range(volume.shape[0]):
            filtered[i] = filters.gaussian(
                volume[i].astype(np.float64),
                sigma=sigma_spatial
            )

        return filtered


class CurtainEffectRemoval:
    """FIB-SEM 커튼 효과(curtaining artifact) 제거"""

    @staticmethod
    def fft_filter(volume: np.ndarray, orientation: str = 'vertical') -> np.ndarray:
        """
        FFT 기반 커튼 효과 제거

        Args:
            volume: 3D 볼륨
            orientation: 커튼 방향 ('vertical' 또는 'horizontal')

        Returns:
            필터링된 볼륨
        """
        filtered = np.zeros_like(volume, dtype=np.float64)

        for i in range(volume.shape[0]):
            slice_2d = volume[i].astype(np.float64)

            # FFT
            f_transform = np.fft.fft2(slice_2d)
            f_shift = np.fft.fftshift(f_transform)

            # 방향에 따른 필터 생성
            rows, cols = slice_2d.shape
            if orientation == 'vertical':
                # 수직 스트라이프 제거: 중앙 열 주변 억제
                center_col = cols // 2
                f_shift[:, center_col-2:center_col+3] *= 0.1
            else:
                # 수평 스트라이프 제거
                center_row = rows // 2
                f_shift[center_row-2:center_row+3, :] *= 0.1

            # 역 FFT
            f_ishift = np.fft.ifftshift(f_shift)
            filtered[i] = np.abs(np.fft.ifft2(f_ishift))

        return filtered
```

### 3.4.3 정규화 및 크기 조정

```python
import numpy as np
from skimage import transform


class Normalization:
    """이미지 정규화 유틸리티"""

    @staticmethod
    def min_max_normalize(volume: np.ndarray) -> np.ndarray:
        """[0, 1] 범위로 정규화"""
        v_min, v_max = volume.min(), volume.max()
        if v_max - v_min == 0:
            return np.zeros_like(volume, dtype=np.float32)
        return (volume - v_min) / (v_max - v_min)

    @staticmethod
    def z_score_normalize(volume: np.ndarray) -> np.ndarray:
        """Z-score 정규화 (평균 0, 표준편차 1)"""
        mean = volume.mean()
        std = volume.std()
        if std == 0:
            return np.zeros_like(volume, dtype=np.float32)
        return (volume - mean) / std

    @staticmethod
    def percentile_normalize(volume: np.ndarray,
                             low: float = 1,
                             high: float = 99) -> np.ndarray:
        """백분위수 기반 정규화 (이상치 영향 감소)"""
        p_low = np.percentile(volume, low)
        p_high = np.percentile(volume, high)
        clipped = np.clip(volume, p_low, p_high)
        return (clipped - p_low) / (p_high - p_low)


class Resizing:
    """볼륨 크기 조정"""

    @staticmethod
    def resize_volume(volume: np.ndarray,
                      target_size: tuple,
                      order: int = 1) -> np.ndarray:
        """
        3D 볼륨 크기 조정

        Args:
            volume: 입력 볼륨
            target_size: 목표 크기 (D, H, W)
            order: 보간 차수 (0: nearest, 1: bilinear, 3: bicubic)
        """
        scale_factors = [t / s for t, s in zip(target_size, volume.shape)]
        return transform.rescale(
            volume,
            scale_factors,
            order=order,
            preserve_range=True,
            anti_aliasing=order > 0
        )

    @staticmethod
    def pad_to_size(volume: np.ndarray,
                    target_size: tuple,
                    mode: str = 'constant') -> np.ndarray:
        """
        볼륨을 목표 크기로 패딩

        Args:
            volume: 입력 볼륨
            target_size: 목표 크기
            mode: 패딩 모드 ('constant', 'edge', 'reflect')
        """
        pad_widths = []
        for s, t in zip(volume.shape, target_size):
            total_pad = max(0, t - s)
            pad_before = total_pad // 2
            pad_after = total_pad - pad_before
            pad_widths.append((pad_before, pad_after))

        return np.pad(volume, pad_widths, mode=mode)
```

### 3.4.4 데이터 증강

```python
import numpy as np
from scipy import ndimage
import torch


class VolumeAugmentation:
    """3D 볼륨 데이터 증강"""

    @staticmethod
    def random_flip_3d(volume: np.ndarray, p: float = 0.5) -> np.ndarray:
        """랜덤 플립 (각 축에 대해)"""
        result = volume.copy()
        for axis in range(3):
            if np.random.random() < p:
                result = np.flip(result, axis=axis)
        return result.copy()  # 연속 메모리로 변환

    @staticmethod
    def random_rotation_90(volume: np.ndarray, p: float = 0.5) -> np.ndarray:
        """90도 단위 랜덤 회전"""
        result = volume.copy()
        if np.random.random() < p:
            k = np.random.randint(1, 4)  # 90, 180, 270도
            axes = np.random.choice([0, 1, 2], size=2, replace=False)
            result = np.rot90(result, k=k, axes=axes)
        return result.copy()

    @staticmethod
    def random_crop_3d(volume: np.ndarray,
                       crop_size: tuple,
                       n_crops: int = 1) -> list:
        """
        랜덤 크롭

        Args:
            volume: 입력 볼륨
            crop_size: 크롭 크기 (D, H, W)
            n_crops: 생성할 크롭 수

        Returns:
            크롭된 볼륨 리스트
        """
        D, H, W = volume.shape
        cd, ch, cw = crop_size

        crops = []
        for _ in range(n_crops):
            d = np.random.randint(0, D - cd + 1)
            h = np.random.randint(0, H - ch + 1)
            w = np.random.randint(0, W - cw + 1)

            crop = volume[d:d+cd, h:h+ch, w:w+cw]
            crops.append(crop)

        return crops

    @staticmethod
    def elastic_deformation_3d(volume: np.ndarray,
                               alpha: float = 100,
                               sigma: float = 10) -> np.ndarray:
        """
        탄성 변형 (Elastic Deformation)

        - 실제 미세구조 변형 모사
        - 데이터 다양성 증가
        """
        shape = volume.shape
        random_state = np.random.RandomState(None)

        # 변형 필드 생성
        dx = ndimage.gaussian_filter(
            (random_state.rand(*shape) * 2 - 1), sigma
        ) * alpha
        dy = ndimage.gaussian_filter(
            (random_state.rand(*shape) * 2 - 1), sigma
        ) * alpha
        dz = ndimage.gaussian_filter(
            (random_state.rand(*shape) * 2 - 1), sigma
        ) * alpha

        # 좌표 그리드
        z, y, x = np.meshgrid(
            np.arange(shape[0]),
            np.arange(shape[1]),
            np.arange(shape[2]),
            indexing='ij'
        )

        # 변형된 좌표
        indices = [
            np.reshape(z + dz, (-1, 1)),
            np.reshape(y + dy, (-1, 1)),
            np.reshape(x + dx, (-1, 1))
        ]

        # 보간
        return ndimage.map_coordinates(
            volume, indices, order=1, mode='reflect'
        ).reshape(shape)
```

---

## 3.5 품질 평가 메트릭

### 3.5.1 구조적 특성 메트릭

```python
import numpy as np
from scipy import ndimage
from skimage import measure


class MicrostructureMetrics:
    """미세구조 품질 평가 메트릭"""

    @staticmethod
    def volume_fraction(labels: np.ndarray, phase_id: int) -> float:
        """
        체적 분율 (Volume Fraction)

        특정 상(phase)이 전체 볼륨에서 차지하는 비율
        """
        return (labels == phase_id).sum() / labels.size

    @staticmethod
    def porosity(labels: np.ndarray, pore_id: int = 1) -> float:
        """기공률 = 기공의 체적 분율"""
        return MicrostructureMetrics.volume_fraction(labels, pore_id)

    @staticmethod
    def specific_surface_area(labels: np.ndarray,
                              phase_id: int,
                              voxel_size: float = 1.0) -> float:
        """
        비표면적 (Specific Surface Area)

        단위 체적당 표면적 (1/length 단위)

        Args:
            labels: 레이블 볼륨
            phase_id: 측정할 상의 ID
            voxel_size: 복셀 크기 (물리적 단위)
        """
        binary = (labels == phase_id).astype(np.uint8)

        # Marching cubes로 표면 추출
        verts, faces, _, _ = measure.marching_cubes(
            binary.astype(np.float64),
            level=0.5,
            spacing=(voxel_size, voxel_size, voxel_size)
        )

        # 삼각형 면적 계산
        surface_area = measure.mesh_surface_area(verts, faces)

        # 총 체적
        total_volume = labels.size * (voxel_size ** 3)

        return surface_area / total_volume

    @staticmethod
    def interface_area(labels: np.ndarray,
                       phase1: int,
                       phase2: int,
                       voxel_size: float = 1.0) -> float:
        """
        두 상 사이의 계면 면적

        배터리에서는 활물질-기공 계면이 반응 면적을 결정
        """
        # 인접 복셀 비교로 계면 검출
        interface = np.zeros_like(labels, dtype=bool)

        for axis in range(3):
            # 정방향
            shifted = np.roll(labels, 1, axis=axis)
            interface |= ((labels == phase1) & (shifted == phase2))
            interface |= ((labels == phase2) & (shifted == phase1))

        # 계면 면적 계산
        interface_voxels = interface.sum()
        # 각 면의 면적
        face_area = voxel_size ** 2

        return interface_voxels * face_area

    @staticmethod
    def tortuosity_factor(labels: np.ndarray,
                          phase_id: int,
                          direction: str = 'z') -> float:
        """
        굴곡도 (Tortuosity Factor)

        실제 이동 경로 길이 / 직선 거리
        확산 저항을 나타내는 중요한 지표

        간단한 근사 방법 (실제로는 시뮬레이션 필요)
        """
        binary = (labels == phase_id).astype(np.float64)

        # 연결성 확인
        labeled, num_features = ndimage.label(binary)

        # 방향에 따른 시작/끝 면
        axis_map = {'x': 2, 'y': 1, 'z': 0}
        axis = axis_map[direction]

        # 관통 경로가 있는지 확인
        if axis == 0:
            start_labels = set(labeled[0, :, :].flatten())
            end_labels = set(labeled[-1, :, :].flatten())
        elif axis == 1:
            start_labels = set(labeled[:, 0, :].flatten())
            end_labels = set(labeled[:, -1, :].flatten())
        else:
            start_labels = set(labeled[:, :, 0].flatten())
            end_labels = set(labeled[:, :, -1].flatten())

        # 관통 여부
        percolating_labels = (start_labels & end_labels) - {0}

        if not percolating_labels:
            return float('inf')  # 관통 경로 없음

        # 간단한 굴곡도 근사: 체적분율의 역수
        epsilon = MicrostructureMetrics.volume_fraction(labels, phase_id)
        tau = 1.0 / epsilon  # Bruggeman 근사

        return tau
```

### 3.5.2 통계적 유사성 메트릭

```python
import numpy as np
from scipy import ndimage


class StatisticalMetrics:
    """원본과 생성 구조 간 통계적 유사성 평가"""

    @staticmethod
    def two_point_correlation(volume: np.ndarray,
                              max_distance: int = 20) -> np.ndarray:
        """
        2점 상관 함수 (Two-Point Correlation)

        S2(r) = P(두 점이 모두 동일 상에 있을 확률)

        미세구조의 공간적 상관관계를 특성화
        """
        binary = volume.astype(np.float64)

        # FFT 기반 자기상관 계산
        f_volume = np.fft.fftn(binary)
        autocorr = np.fft.ifftn(f_volume * np.conj(f_volume)).real
        autocorr /= autocorr[0, 0, 0]  # 정규화

        # 거리별 평균
        shape = autocorr.shape
        center = [s // 2 for s in shape]

        distances = []
        values = []

        for d in range(max_distance):
            # 거리 d에 해당하는 복셀들의 상관값 평균
            mask = np.zeros(shape, dtype=bool)
            # 간단히 z축 방향만 계산
            if d < center[0]:
                mask[d, center[1], center[2]] = True
                mask[-d if d > 0 else 0, center[1], center[2]] = True

            if mask.any():
                distances.append(d)
                values.append(autocorr[mask].mean())

        return np.array([distances, values])

    @staticmethod
    def chord_length_distribution(labels: np.ndarray,
                                  phase_id: int,
                                  direction: str = 'z',
                                  n_samples: int = 1000) -> tuple:
        """
        현 길이 분포 (Chord Length Distribution)

        임의의 선이 특정 상을 통과하는 길이의 분포
        입자 크기 분포와 관련
        """
        binary = (labels == phase_id).astype(np.uint8)
        shape = labels.shape

        chord_lengths = []

        for _ in range(n_samples):
            # 랜덤 시작점
            if direction == 'z':
                y, x = np.random.randint(0, shape[1]), np.random.randint(0, shape[2])
                line = binary[:, y, x]
            elif direction == 'y':
                z, x = np.random.randint(0, shape[0]), np.random.randint(0, shape[2])
                line = binary[z, :, x]
            else:
                z, y = np.random.randint(0, shape[0]), np.random.randint(0, shape[1])
                line = binary[z, y, :]

            # 연속된 1의 길이 계산
            labeled_line, n_features = ndimage.label(line)
            if n_features > 0:
                for i in range(1, n_features + 1):
                    chord_lengths.append((labeled_line == i).sum())

        chord_lengths = np.array(chord_lengths)

        # 히스토그램 반환
        hist, bins = np.histogram(chord_lengths, bins=50, density=True)
        return bins[:-1], hist

    @staticmethod
    def compare_distributions(dist1: tuple, dist2: tuple) -> dict:
        """두 분포의 유사성 비교"""
        from scipy.stats import wasserstein_distance, ks_2samp

        # Wasserstein distance (Earth Mover's Distance)
        w_dist = wasserstein_distance(dist1[1], dist2[1])

        # Kolmogorov-Smirnov 검정
        ks_stat, ks_pvalue = ks_2samp(dist1[1], dist2[1])

        return {
            'wasserstein_distance': w_dist,
            'ks_statistic': ks_stat,
            'ks_pvalue': ks_pvalue
        }
```

---

## 3.6 전처리 파이프라인 통합

```python
from dataclasses import dataclass
from typing import Optional
import numpy as np


@dataclass
class PreprocessingConfig:
    """전처리 설정"""
    # 필터링
    apply_median_filter: bool = True
    median_filter_size: int = 3

    apply_gaussian_filter: bool = False
    gaussian_sigma: float = 1.0

    # 커튼 효과 제거
    remove_curtaining: bool = False
    curtain_orientation: str = 'vertical'

    # 정규화
    normalization: str = 'min_max'  # 'min_max', 'z_score', 'percentile'

    # 크기 조정
    target_size: Optional[tuple] = (64, 64, 64)
    resize_order: int = 1


class PreprocessingPipeline:
    """전처리 파이프라인"""

    def __init__(self, config: PreprocessingConfig):
        self.config = config

    def __call__(self, volume: np.ndarray) -> np.ndarray:
        """
        전처리 파이프라인 실행

        Args:
            volume: 입력 3D 볼륨

        Returns:
            전처리된 볼륨
        """
        result = volume.copy().astype(np.float64)

        # 1. 노이즈 필터링
        if self.config.apply_median_filter:
            result = NoiseFilters.median_filter_3d(
                result, size=self.config.median_filter_size
            )

        if self.config.apply_gaussian_filter:
            result = NoiseFilters.gaussian_filter_3d(
                result, sigma=self.config.gaussian_sigma
            )

        # 2. 커튼 효과 제거
        if self.config.remove_curtaining:
            result = CurtainEffectRemoval.fft_filter(
                result, orientation=self.config.curtain_orientation
            )

        # 3. 정규화
        if self.config.normalization == 'min_max':
            result = Normalization.min_max_normalize(result)
        elif self.config.normalization == 'z_score':
            result = Normalization.z_score_normalize(result)
        elif self.config.normalization == 'percentile':
            result = Normalization.percentile_normalize(result)

        # 4. 크기 조정
        if self.config.target_size:
            result = Resizing.resize_volume(
                result,
                self.config.target_size,
                order=self.config.resize_order
            )

        return result.astype(np.float32)


# 사용 예시
if __name__ == "__main__":
    # 설정
    config = PreprocessingConfig(
        apply_median_filter=True,
        median_filter_size=3,
        normalization='min_max',
        target_size=(64, 64, 64)
    )

    # 파이프라인 생성
    pipeline = PreprocessingPipeline(config)

    # 데이터 로딩
    loader = ImageLoader()
    raw_volume = loader.load_image("data/raw/sample.tif")

    # 전처리 실행
    processed_volume = pipeline(raw_volume)

    print(f"Input shape: {raw_volume.shape}")
    print(f"Output shape: {processed_volume.shape}")
    print(f"Output range: [{processed_volume.min():.3f}, {processed_volume.max():.3f}]")
```

---

## 3.7 참고 자료

### 데이터 및 분할 관련

| 자료 | 링크 | 설명 |
|------|------|------|
| NREL Battery Microstructure | [NREL](https://www.nrel.gov/transportation/battery-microstructure-library-data) | 공개 배터리 미세구조 데이터 |
| 3D U-Net 논문 | [PMC](https://pmc.ncbi.nlm.nih.gov/articles/PMC8551326/) | 3D U-Net 분할 방법론 |
| Swin UNETR | [Nature](https://www.nature.com/articles/s41524-024-01226-5) | Transformer 기반 분할 |

### 추가 자료

1. **pyStackReg**: FIB-SEM 슬라이스 정렬 도구
2. **MONAI**: 의료/과학 영상 딥러닝 프레임워크
3. **scikit-image**: 과학 이미지 처리 라이브러리

---

# Part 4: Blender + COMSOL 연계 워크플로우

## 4.1 개요

생성된 3D 복셀 구조를 실제 전기화학 시뮬레이션에 사용하려면 메시(mesh) 변환과 시뮬레이션 소프트웨어로의 내보내기가 필요합니다. 본 섹션에서는 복셀→메시 변환, Blender Python API 활용, 그리고 COMSOL 연계 방법을 다룹니다.

### 전체 워크플로우

```
┌─────────────────────────────────────────────────────────────────────────┐
│                      전체 워크플로우 다이어그램                            │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                         │
│  ┌──────────────┐                                                       │
│  │ 2D SEM Image │                                                       │
│  └──────┬───────┘                                                       │
│         │                                                               │
│         ▼                                                               │
│  ┌──────────────┐    ┌──────────────┐    ┌──────────────┐              │
│  │ Segmentation │───►│  SliceGAN   │───►│ 3D Voxel     │              │
│  │ (U-Net)      │    │ (생성)       │    │ (64³×3)      │              │
│  └──────────────┘    └──────────────┘    └──────┬───────┘              │
│                                                 │                       │
│                                                 ▼                       │
│                                   ┌──────────────────────┐             │
│                                   │ Marching Cubes       │             │
│                                   │ (scikit-image)       │             │
│                                   └──────────┬───────────┘             │
│                                              │                         │
│                                              ▼                         │
│                        ┌──────────────────────────────────┐            │
│                        │ Surface Mesh (STL/OBJ)           │            │
│                        │ • trimesh / PyVista              │            │
│                        └──────────────┬───────────────────┘            │
│                                       │                                │
│                    ┌──────────────────┼──────────────────┐             │
│                    │                  │                  │             │
│                    ▼                  ▼                  ▼             │
│             ┌───────────┐      ┌───────────┐      ┌───────────┐       │
│             │ Blender   │      │ Gmsh      │      │ Direct    │       │
│             │ (bpy)     │      │ (FEM mesh)│      │ Import    │       │
│             │ 정제/시각화│      │ 테트라메시 │      │ to COMSOL │       │
│             └─────┬─────┘      └─────┬─────┘      └─────┬─────┘       │
│                   │                  │                  │             │
│                   └──────────────────┼──────────────────┘             │
│                                      ▼                                │
│                         ┌──────────────────────┐                      │
│                         │ COMSOL Multiphysics  │                      │
│                         │ • 전기화학 시뮬레이션    │                      │
│                         │ • 리튬 이온 전지 모듈   │                      │
│                         └──────────────────────┘                      │
│                                                                         │
└─────────────────────────────────────────────────────────────────────────┘
```

---

## 4.2 복셀 → 메시 변환

### 4.2.1 Marching Cubes 알고리즘

Marching Cubes는 3D 복셀 데이터에서 등가면(isosurface)을 추출하는 표준 알고리즘입니다.

```python
import numpy as np
from skimage import measure
import trimesh


class VoxelToMesh:
    """복셀 데이터를 메시로 변환"""

    @staticmethod
    def marching_cubes(volume: np.ndarray,
                       level: float = 0.5,
                       spacing: tuple = (1.0, 1.0, 1.0),
                       step_size: int = 1) -> trimesh.Trimesh:
        """
        Marching Cubes를 사용한 메시 생성

        Args:
            volume: 3D 복셀 데이터 (0-1 범위)
            level: 등가면 레벨 (0.5 = 경계)
            spacing: 복셀 간격 (물리적 단위)
            step_size: 샘플링 간격 (1 = 전체, 2 = 절반 해상도)

        Returns:
            trimesh.Trimesh 객체
        """
        # Marching Cubes 실행
        verts, faces, normals, values = measure.marching_cubes(
            volume.astype(np.float64),
            level=level,
            spacing=spacing,
            step_size=step_size,
            allow_degenerate=False
        )

        # Trimesh 객체 생성
        mesh = trimesh.Trimesh(
            vertices=verts,
            faces=faces,
            vertex_normals=normals
        )

        return mesh

    @staticmethod
    def multiphase_to_mesh(labels: np.ndarray,
                           spacing: tuple = (1.0, 1.0, 1.0)) -> dict:
        """
        다상(multi-phase) 복셀을 각 상별 메시로 변환

        Args:
            labels: 정수 레이블 볼륨 (0, 1, 2, ...)
            spacing: 복셀 간격

        Returns:
            {phase_id: trimesh.Trimesh} 딕셔너리
        """
        meshes = {}
        unique_labels = np.unique(labels)

        for label in unique_labels:
            # 해당 상만 추출 (이진 볼륨)
            binary = (labels == label).astype(np.float64)

            # 가장자리 패딩 (메시 폐쇄를 위해)
            padded = np.pad(binary, pad_width=1, mode='constant', constant_values=0)

            # 복셀이 충분한 경우에만 메시 생성
            if binary.sum() > 10:
                try:
                    mesh = VoxelToMesh.marching_cubes(
                        padded, level=0.5, spacing=spacing
                    )
                    meshes[int(label)] = mesh
                except RuntimeError:
                    print(f"Warning: Could not create mesh for phase {label}")

        return meshes

    @staticmethod
    def export_mesh(mesh: trimesh.Trimesh,
                    filepath: str,
                    file_format: str = None):
        """
        메시를 파일로 내보내기

        지원 포맷: STL, OBJ, PLY, OFF, GLB, GLTF
        """
        mesh.export(filepath, file_type=file_format)
        print(f"Exported mesh to: {filepath}")
        print(f"  Vertices: {len(mesh.vertices)}")
        print(f"  Faces: {len(mesh.faces)}")
```

### 4.2.2 메시 정제

```python
import trimesh
import numpy as np


class MeshRefinement:
    """메시 품질 개선 및 정제"""

    @staticmethod
    def smooth_mesh(mesh: trimesh.Trimesh,
                    iterations: int = 10,
                    lamb: float = 0.5) -> trimesh.Trimesh:
        """
        라플라시안 스무딩

        Args:
            mesh: 입력 메시
            iterations: 반복 횟수
            lamb: 스무딩 강도 (0-1)

        Returns:
            스무딩된 메시
        """
        # Trimesh의 내장 스무딩 사용
        smoothed = mesh.copy()
        trimesh.smoothing.filter_laplacian(
            smoothed,
            lamb=lamb,
            iterations=iterations
        )
        return smoothed

    @staticmethod
    def decimate_mesh(mesh: trimesh.Trimesh,
                      target_faces: int = None,
                      ratio: float = 0.5) -> trimesh.Trimesh:
        """
        메시 단순화 (면 수 감소)

        Args:
            mesh: 입력 메시
            target_faces: 목표 면 수 (None이면 ratio 사용)
            ratio: 감소 비율 (0.5 = 절반)

        Returns:
            단순화된 메시
        """
        if target_faces is None:
            target_faces = int(len(mesh.faces) * ratio)

        # 단순화 실행
        simplified = mesh.simplify_quadric_decimation(target_faces)
        return simplified

    @staticmethod
    def repair_mesh(mesh: trimesh.Trimesh) -> trimesh.Trimesh:
        """
        메시 결함 수리

        - 중복 정점 제거
        - 퇴화 면 제거
        - 법선 일관성 수정
        """
        repaired = mesh.copy()

        # 중복 정점 병합
        repaired.merge_vertices()

        # 퇴화 면 제거
        repaired.remove_degenerate_faces()

        # 법선 일관성
        repaired.fix_normals()

        return repaired

    @staticmethod
    def check_mesh_quality(mesh: trimesh.Trimesh) -> dict:
        """
        메시 품질 검사

        Returns:
            품질 지표 딕셔너리
        """
        return {
            'is_watertight': mesh.is_watertight,
            'is_winding_consistent': mesh.is_winding_consistent,
            'euler_number': mesh.euler_number,
            'n_vertices': len(mesh.vertices),
            'n_faces': len(mesh.faces),
            'surface_area': mesh.area,
            'volume': mesh.volume if mesh.is_watertight else None,
            'bounds': mesh.bounds.tolist()
        }
```

---

## 4.3 Blender Python API (bpy)

### 4.3.1 헤드리스 모드 설정

```python
"""
Blender Python API (bpy) 기본 사용법

실행 방법:
1. Blender 내부: 스크립팅 탭에서 실행
2. 명령줄 헤드리스: blender --background --python script.py

설치:
- Blender 설치 시 bpy 자동 포함
- pip install bpy (독립 실행형, 제한적)
"""

# 헤드리스 실행 스크립트 예시
BLENDER_HEADLESS_SCRIPT = '''
#!/usr/bin/env python
"""
Blender 헤드리스 실행 스크립트

사용법:
    blender --background --python this_script.py -- [arguments]
"""

import sys
import argparse

# Blender 모듈 임포트
try:
    import bpy
    import bmesh
    from mathutils import Vector
except ImportError:
    print("Error: This script must be run from within Blender")
    print("Usage: blender --background --python script.py")
    sys.exit(1)


def clear_scene():
    """씬 초기화 - 모든 객체 삭제"""
    bpy.ops.object.select_all(action='SELECT')
    bpy.ops.object.delete(use_global=False)


def setup_scene():
    """기본 씬 설정"""
    # 단위 설정 (미터 → 마이크로미터)
    bpy.context.scene.unit_settings.system = 'METRIC'
    bpy.context.scene.unit_settings.scale_length = 1e-6  # 1 unit = 1 μm

    # 렌더링 설정
    bpy.context.scene.render.engine = 'CYCLES'
    bpy.context.scene.cycles.device = 'GPU'


def main():
    """메인 실행 함수"""
    # 인자 파싱 (-- 이후의 인자)
    argv = sys.argv
    if "--" in argv:
        argv = argv[argv.index("--") + 1:]

    parser = argparse.ArgumentParser()
    parser.add_argument("--input", type=str, required=True, help="Input STL file")
    parser.add_argument("--output", type=str, required=True, help="Output file")
    args = parser.parse_args(argv)

    # 씬 초기화
    clear_scene()
    setup_scene()

    # 메시 가져오기
    bpy.ops.import_mesh.stl(filepath=args.input)

    # 처리...

    # 내보내기
    bpy.ops.export_mesh.stl(filepath=args.output)

    print(f"Processing complete: {args.output}")


if __name__ == "__main__":
    main()
'''
```

### 4.3.2 프로그래매틱 메시 생성/조작

```python
"""
Blender bpy를 사용한 메시 조작
"""

import bpy
import bmesh
import numpy as np
from mathutils import Vector


class BlenderMeshOperations:
    """Blender 메시 연산 클래스"""

    @staticmethod
    def import_stl(filepath: str, name: str = "ImportedMesh") -> bpy.types.Object:
        """
        STL 파일 가져오기

        Args:
            filepath: STL 파일 경로
            name: 객체 이름

        Returns:
            Blender 객체
        """
        bpy.ops.import_mesh.stl(filepath=filepath)
        obj = bpy.context.active_object
        obj.name = name
        return obj

    @staticmethod
    def import_obj(filepath: str, name: str = "ImportedMesh") -> bpy.types.Object:
        """OBJ 파일 가져오기"""
        bpy.ops.import_scene.obj(filepath=filepath)
        obj = bpy.context.selected_objects[0]
        obj.name = name
        return obj

    @staticmethod
    def smooth_mesh(obj: bpy.types.Object,
                    iterations: int = 10,
                    factor: float = 0.5):
        """
        메시 스무딩 (Blender 내장)

        Args:
            obj: Blender 메시 객체
            iterations: 반복 횟수
            factor: 스무딩 강도
        """
        # 객체 선택 및 활성화
        bpy.context.view_layer.objects.active = obj
        obj.select_set(True)

        # Edit 모드 전환
        bpy.ops.object.mode_set(mode='EDIT')

        # 모든 버텍스 선택
        bpy.ops.mesh.select_all(action='SELECT')

        # 스무딩 적용
        for _ in range(iterations):
            bpy.ops.mesh.vertices_smooth(factor=factor)

        # Object 모드로 복귀
        bpy.ops.object.mode_set(mode='OBJECT')

    @staticmethod
    def decimate_mesh(obj: bpy.types.Object, ratio: float = 0.5):
        """
        Decimate 모디파이어를 사용한 메시 단순화

        Args:
            obj: Blender 메시 객체
            ratio: 유지할 면의 비율 (0.5 = 절반)
        """
        # Decimate 모디파이어 추가
        modifier = obj.modifiers.new(name="Decimate", type='DECIMATE')
        modifier.ratio = ratio
        modifier.decimate_type = 'COLLAPSE'

        # 모디파이어 적용
        bpy.context.view_layer.objects.active = obj
        bpy.ops.object.modifier_apply(modifier="Decimate")

    @staticmethod
    def remesh(obj: bpy.types.Object,
               voxel_size: float = 0.1,
               adaptivity: float = 0.0):
        """
        Remesh 모디파이어를 사용한 메시 재생성

        균일한 토폴로지 생성에 유용

        Args:
            obj: Blender 메시 객체
            voxel_size: 복셀 크기
            adaptivity: 적응형 메싱 (0 = 균일)
        """
        modifier = obj.modifiers.new(name="Remesh", type='REMESH')
        modifier.mode = 'VOXEL'
        modifier.voxel_size = voxel_size
        modifier.adaptivity = adaptivity

        bpy.context.view_layer.objects.active = obj
        bpy.ops.object.modifier_apply(modifier="Remesh")

    @staticmethod
    def export_stl(obj: bpy.types.Object, filepath: str, ascii: bool = False):
        """
        STL로 내보내기

        Args:
            obj: Blender 메시 객체
            filepath: 출력 경로
            ascii: ASCII 형식 여부 (False = 바이너리)
        """
        # 다른 객체 선택 해제
        bpy.ops.object.select_all(action='DESELECT')
        obj.select_set(True)

        # 내보내기
        bpy.ops.export_mesh.stl(
            filepath=filepath,
            use_selection=True,
            ascii=ascii
        )

    @staticmethod
    def export_obj(obj: bpy.types.Object, filepath: str):
        """OBJ로 내보내기"""
        bpy.ops.object.select_all(action='DESELECT')
        obj.select_set(True)

        bpy.ops.export_scene.obj(
            filepath=filepath,
            use_selection=True
        )


class BlenderMaterialAssignment:
    """Blender 재질 할당"""

    @staticmethod
    def create_material(name: str, color: tuple) -> bpy.types.Material:
        """
        기본 재질 생성

        Args:
            name: 재질 이름
            color: RGBA 색상 (0-1 범위)

        Returns:
            Blender 재질
        """
        mat = bpy.data.materials.new(name=name)
        mat.use_nodes = True

        # Principled BSDF 노드 설정
        bsdf = mat.node_tree.nodes["Principled BSDF"]
        bsdf.inputs["Base Color"].default_value = color

        return mat

    @staticmethod
    def assign_material(obj: bpy.types.Object, material: bpy.types.Material):
        """객체에 재질 할당"""
        if obj.data.materials:
            obj.data.materials[0] = material
        else:
            obj.data.materials.append(material)

    @staticmethod
    def create_electrode_materials() -> dict:
        """
        배터리 전극 상별 재질 생성

        Returns:
            {phase_name: material} 딕셔너리
        """
        materials = {}

        # 활물질 (빨강)
        materials['active_material'] = BlenderMaterialAssignment.create_material(
            "ActiveMaterial",
            (0.8, 0.2, 0.2, 1.0)  # RGBA
        )

        # 기공 (투명 파랑)
        mat_pore = BlenderMaterialAssignment.create_material(
            "Pore",
            (0.2, 0.4, 0.8, 0.3)
        )
        mat_pore.blend_method = 'BLEND'  # 투명도 활성화
        materials['pore'] = mat_pore

        # 바인더/CBD (회색)
        materials['binder'] = BlenderMaterialAssignment.create_material(
            "Binder",
            (0.5, 0.5, 0.5, 1.0)
        )

        return materials
```

---

## 4.4 Gmsh를 사용한 FEM 메시 생성

### 4.4.1 Gmsh Python API

```python
"""
Gmsh Python API를 사용한 FEM 메시 생성

설치:
    pip install gmsh

참고:
    https://gmsh.info/
    https://jsdokken.com/src/tutorial_gmsh.html
"""

import gmsh
import numpy as np


class GmshMeshGenerator:
    """Gmsh를 사용한 FEM 메시 생성"""

    def __init__(self):
        """Gmsh 초기화"""
        gmsh.initialize()
        gmsh.option.setNumber("General.Terminal", 1)  # 터미널 출력

    def __del__(self):
        """Gmsh 종료"""
        gmsh.finalize()

    def load_stl(self, filepath: str, name: str = "surface"):
        """
        STL 파일 로딩

        Args:
            filepath: STL 파일 경로
            name: 지오메트리 이름
        """
        gmsh.model.add(name)
        gmsh.merge(filepath)

    def create_volume_from_surface(self):
        """
        표면 메시에서 볼륨 생성

        STL은 표면만 정의하므로 볼륨을 생성해야 함
        """
        # 표면 루프 생성
        gmsh.model.geo.synchronize()

        # 표면에서 볼륨 생성 시도
        try:
            gmsh.model.mesh.createGeometry()
            gmsh.model.geo.synchronize()
        except Exception as e:
            print(f"Warning: {e}")

    def set_mesh_size(self,
                      min_size: float = 0.1,
                      max_size: float = 1.0,
                      curvature_adapt: bool = True):
        """
        메시 크기 설정

        Args:
            min_size: 최소 요소 크기
            max_size: 최대 요소 크기
            curvature_adapt: 곡률 적응형 메싱
        """
        gmsh.option.setNumber("Mesh.MeshSizeMin", min_size)
        gmsh.option.setNumber("Mesh.MeshSizeMax", max_size)

        if curvature_adapt:
            # 곡률 기반 자동 크기 조정
            gmsh.option.setNumber("Mesh.MeshSizeFromCurvature", 1)
            gmsh.option.setNumber("Mesh.MinimumElementsPerTwoPi", 12)

    def generate_mesh(self, dim: int = 3, algorithm: str = "Delaunay"):
        """
        메시 생성

        Args:
            dim: 차원 (2 = 표면, 3 = 볼륨)
            algorithm: 메싱 알고리즘
                - "Delaunay": 기본 Delaunay
                - "Frontal": Frontal-Delaunay
                - "HXT": 병렬 HXT (빠름)
        """
        algorithms = {
            "Delaunay": 1,
            "Frontal": 4,
            "HXT": 10
        }

        if algorithm in algorithms:
            gmsh.option.setNumber(f"Mesh.Algorithm{dim}D", algorithms[algorithm])

        gmsh.model.mesh.generate(dim)

    def optimize_mesh(self, method: str = "Netgen"):
        """
        메시 최적화

        Args:
            method: 최적화 방법 ("Netgen", "Laplace", "Relocate")
        """
        gmsh.model.mesh.optimize(method)

    def export_mesh(self, filepath: str, file_format: str = None):
        """
        메시 내보내기

        지원 포맷:
        - .msh: Gmsh 네이티브
        - .vtk: VTK 형식
        - .nas/.bdf: Nastran (COMSOL 호환)
        - .inp: Abaqus
        - .stl: STL (표면만)

        Args:
            filepath: 출력 경로
            file_format: 파일 형식 (None = 확장자에서 추론)
        """
        gmsh.write(filepath)
        print(f"Exported mesh to: {filepath}")

    def get_mesh_statistics(self) -> dict:
        """메시 통계 정보 반환"""
        node_tags, node_coords, _ = gmsh.model.mesh.getNodes()
        element_types, element_tags, element_node_tags = gmsh.model.mesh.getElements()

        stats = {
            'n_nodes': len(node_tags),
            'n_elements': sum(len(tags) for tags in element_tags),
            'element_types': element_types.tolist() if hasattr(element_types, 'tolist') else list(element_types),
            'bounds': {
                'min': node_coords.reshape(-1, 3).min(axis=0).tolist(),
                'max': node_coords.reshape(-1, 3).max(axis=0).tolist()
            }
        }

        return stats


def stl_to_fem_mesh(input_stl: str,
                    output_path: str,
                    mesh_size: float = 0.5) -> dict:
    """
    STL을 FEM 메시로 변환하는 편의 함수

    Args:
        input_stl: 입력 STL 파일
        output_path: 출력 메시 파일 (.msh, .nas 등)
        mesh_size: 메시 요소 크기

    Returns:
        메시 통계 딕셔너리
    """
    generator = GmshMeshGenerator()

    # STL 로딩
    generator.load_stl(input_stl)

    # 메시 크기 설정
    generator.set_mesh_size(
        min_size=mesh_size * 0.5,
        max_size=mesh_size * 2.0
    )

    # 표면 메시 생성
    generator.generate_mesh(dim=2)

    # 볼륨 메시 생성 (테트라헤드럴)
    generator.generate_mesh(dim=3, algorithm="Delaunay")

    # 최적화
    generator.optimize_mesh()

    # 내보내기
    generator.export_mesh(output_path)

    # 통계 반환
    return generator.get_mesh_statistics()
```

---

## 4.5 COMSOL 연계

### 4.5.1 mph 라이브러리 vs LiveLink

| 특징 | mph 라이브러리 | LiveLink for Python |
|------|---------------|---------------------|
| **설치** | `pip install mph` | COMSOL 라이선스 필요 |
| **비용** | 무료 (오픈소스) | 추가 라이선스 비용 |
| **기능** | 기본 모델 조작 | 전체 COMSOL API 접근 |
| **사용 용도** | 자동화, 배치 처리 | 고급 커스터마이징 |

### 4.5.2 mph 라이브러리 사용

```python
"""
mph 라이브러리를 사용한 COMSOL 연계

설치:
    pip install mph

요구사항:
    - COMSOL Multiphysics 설치
    - COMSOL 서버 실행 (standalone 모드)

참고:
    https://mph.readthedocs.io/
"""

import mph
from pathlib import Path


class COMSOLInterface:
    """COMSOL 인터페이스 클래스"""

    def __init__(self):
        """COMSOL 클라이언트 초기화"""
        self.client = None
        self.model = None

    def connect(self):
        """COMSOL 서버 연결"""
        self.client = mph.start()
        print(f"Connected to COMSOL {self.client.version}")

    def disconnect(self):
        """연결 종료"""
        if self.client:
            self.client.disconnect()

    def create_model(self, name: str = "electrode_model"):
        """
        새 모델 생성

        Args:
            name: 모델 이름
        """
        self.model = self.client.create(name)
        return self.model

    def load_model(self, filepath: str):
        """기존 모델 로딩"""
        self.model = self.client.load(filepath)
        return self.model

    def import_mesh(self, mesh_path: str, component: str = "comp1"):
        """
        메시 파일 가져오기

        Args:
            mesh_path: 메시 파일 경로 (.stl, .nas, .msh 등)
            component: COMSOL 컴포넌트 이름
        """
        mesh_path = Path(mesh_path)

        # 지오메트리 시퀀스에서 임포트
        geometry = self.model / 'geometries' / 'geom1'

        if mesh_path.suffix.lower() == '.stl':
            # STL 임포트
            imp = geometry.create('Import', 'imp1')
            imp.property('filename', str(mesh_path))
            imp.run()
        elif mesh_path.suffix.lower() in ['.nas', '.bdf']:
            # Nastran 형식 임포트
            mesh = self.model / 'meshes' / 'mesh1'
            imp = mesh.create('Import', 'imp1')
            imp.property('filename', str(mesh_path))
            imp.property('facepartition', 'automatic')
            imp.run()

    def setup_li_ion_battery(self):
        """
        리튬 이온 전지 물리 설정

        COMSOL Battery & Fuel Cell Module 필요
        """
        physics = self.model / 'physics'

        # 리튬 이온 전지 인터페이스 추가
        liion = physics.create('LithiumIonBattery', 'liion')

        # 기본 설정
        liion.property('T', '298.15[K]')  # 온도

        return liion

    def setup_materials(self):
        """
        배터리 전극 재료 물성 설정
        """
        materials = self.model / 'materials'

        # 활물질 (예: NMC)
        nmc = materials.create('Common', 'mat1')
        nmc.property('family', 'Li-ion battery')
        nmc.label = 'NMC Active Material'

        # 기공 (전해질)
        electrolyte = materials.create('Common', 'mat2')
        electrolyte.label = 'Electrolyte'

        # 바인더/CBD
        binder = materials.create('Common', 'mat3')
        binder.label = 'Binder/CBD'

        return [nmc, electrolyte, binder]

    def run_study(self, study_type: str = 'stationary'):
        """
        스터디 실행

        Args:
            study_type: 'stationary', 'time-dependent', 'parametric'
        """
        study = self.model / 'studies' / 'std1'

        if study_type == 'stationary':
            step = study.create('Stationary', 'stat')
        elif study_type == 'time-dependent':
            step = study.create('Transient', 'trans')
            step.property('tlist', 'range(0, 10, 1000)')  # 0-1000초

        # 솔버 실행
        study.run()

    def export_results(self, output_dir: str):
        """
        결과 내보내기

        Args:
            output_dir: 출력 디렉토리
        """
        output_dir = Path(output_dir)
        output_dir.mkdir(parents=True, exist_ok=True)

        # 데이터 내보내기
        export = self.model / 'exports'

        # 전위 분포
        data_export = export.create('Data', 'data1')
        data_export.property('filename', str(output_dir / 'potential.txt'))
        data_export.run()

        # 이미지 내보내기
        img_export = export.create('Image', 'img1')
        img_export.property('filename', str(output_dir / 'result.png'))
        img_export.run()

    def save_model(self, filepath: str):
        """모델 저장"""
        self.model.save(filepath)
        print(f"Model saved to: {filepath}")


def automated_comsol_workflow(mesh_path: str,
                              output_dir: str,
                              model_name: str = "electrode_sim"):
    """
    자동화된 COMSOL 워크플로우

    Args:
        mesh_path: 입력 메시 파일 경로
        output_dir: 결과 출력 디렉토리
        model_name: 모델 이름
    """
    comsol = COMSOLInterface()

    try:
        # 연결
        comsol.connect()

        # 새 모델 생성
        comsol.create_model(model_name)

        # 메시 임포트
        comsol.import_mesh(mesh_path)

        # 물리 설정
        comsol.setup_li_ion_battery()

        # 재료 설정
        comsol.setup_materials()

        # 스터디 실행
        comsol.run_study('stationary')

        # 결과 내보내기
        comsol.export_results(output_dir)

        # 모델 저장
        comsol.save_model(f"{output_dir}/{model_name}.mph")

    finally:
        comsol.disconnect()
```

### 4.5.3 물성 매핑 자동화

```python
"""
복셀 데이터에서 COMSOL 물성 매핑
"""

import numpy as np


class MaterialPropertyMapper:
    """
    복셀 레이블을 COMSOL 재료 물성에 매핑
    """

    # 배터리 전극 재료 물성 (예시 값)
    ELECTRODE_PROPERTIES = {
        'active_material': {
            'label': 0,
            'name': 'NMC (LiNi0.33Mn0.33Co0.33O2)',
            'properties': {
                'electrical_conductivity': 0.1,        # S/m
                'ionic_diffusivity': 1e-14,            # m²/s
                'density': 4700,                       # kg/m³
                'specific_heat': 700,                  # J/(kg·K)
                'thermal_conductivity': 5,             # W/(m·K)
                'equilibrium_potential': '4.2[V]',     # V (함수로 정의 가능)
                'reaction_rate_constant': 1e-11,       # m/s
                'charge_transfer_coefficient': 0.5,   # 무차원
            }
        },
        'pore': {
            'label': 1,
            'name': 'Electrolyte (LiPF6 in EC/DMC)',
            'properties': {
                'ionic_conductivity': 1.0,            # S/m
                'Li_diffusivity': 3e-10,              # m²/s
                'density': 1200,                      # kg/m³
                'specific_heat': 2000,                # J/(kg·K)
                'transference_number': 0.4,           # 무차원
                'initial_concentration': 1000,        # mol/m³
            }
        },
        'binder_cbd': {
            'label': 2,
            'name': 'PVDF + Carbon Black',
            'properties': {
                'electrical_conductivity': 100,       # S/m (CBD에 의해 높음)
                'density': 1780,                      # kg/m³
                'specific_heat': 1500,                # J/(kg·K)
                'thermal_conductivity': 0.2,          # W/(m·K)
            }
        }
    }

    @classmethod
    def generate_property_file(cls, labels: np.ndarray,
                               voxel_size: float,
                               output_path: str):
        """
        COMSOL 호환 물성 파일 생성

        Args:
            labels: 3D 레이블 볼륨
            voxel_size: 복셀 크기 (m)
            output_path: 출력 파일 경로

        COMSOL에서 Interpolation 함수로 읽을 수 있는 형식으로 저장
        """
        D, H, W = labels.shape

        # 좌표 생성
        z_coords = np.arange(D) * voxel_size
        y_coords = np.arange(H) * voxel_size
        x_coords = np.arange(W) * voxel_size

        # 각 물성별 파일 생성
        for phase_name, phase_info in cls.ELECTRODE_PROPERTIES.items():
            phase_label = phase_info['label']
            phase_mask = (labels == phase_label).astype(np.float64)

            # 전기 전도도 파일 생성
            if 'electrical_conductivity' in phase_info['properties']:
                sigma = phase_info['properties']['electrical_conductivity']
                sigma_field = phase_mask * sigma

                cls._write_comsol_interpolation_file(
                    f"{output_path}_{phase_name}_sigma.txt",
                    x_coords, y_coords, z_coords,
                    sigma_field
                )

    @staticmethod
    def _write_comsol_interpolation_file(filepath: str,
                                         x: np.ndarray,
                                         y: np.ndarray,
                                         z: np.ndarray,
                                         values: np.ndarray):
        """
        COMSOL Interpolation 함수용 파일 작성

        형식:
        % Grid: x y z
        x0 y0 z0 value
        x1 y0 z0 value
        ...
        """
        with open(filepath, 'w') as f:
            f.write(f"% Grid: {len(x)} {len(y)} {len(z)}\n")
            f.write("% x y z value\n")

            for i, xi in enumerate(x):
                for j, yj in enumerate(y):
                    for k, zk in enumerate(z):
                        f.write(f"{xi:.6e} {yj:.6e} {zk:.6e} {values[i,j,k]:.6e}\n")

        print(f"Written: {filepath}")

    @classmethod
    def calculate_effective_properties(cls, labels: np.ndarray) -> dict:
        """
        유효 물성 계산 (균질화 근사)

        Args:
            labels: 3D 레이블 볼륨

        Returns:
            유효 물성 딕셔너리
        """
        total_voxels = labels.size

        effective = {}

        # 각 상의 체적 분율
        for phase_name, phase_info in cls.ELECTRODE_PROPERTIES.items():
            phase_label = phase_info['label']
            volume_fraction = (labels == phase_label).sum() / total_voxels

            effective[f'{phase_name}_volume_fraction'] = volume_fraction

        # 유효 전기 전도도 (Bruggeman 모델)
        epsilon_am = effective['active_material_volume_fraction']
        epsilon_cbd = effective['binder_cbd_volume_fraction']

        sigma_am = cls.ELECTRODE_PROPERTIES['active_material']['properties']['electrical_conductivity']
        sigma_cbd = cls.ELECTRODE_PROPERTIES['binder_cbd']['properties']['electrical_conductivity']

        # 고체상 유효 전도도
        sigma_eff_solid = sigma_am * (epsilon_am ** 1.5) + sigma_cbd * (epsilon_cbd ** 1.5)
        effective['effective_electronic_conductivity'] = sigma_eff_solid

        # 유효 이온 전도도
        epsilon_pore = effective['pore_volume_fraction']
        kappa_elec = cls.ELECTRODE_PROPERTIES['pore']['properties']['ionic_conductivity']
        kappa_eff = kappa_elec * (epsilon_pore ** 1.5)
        effective['effective_ionic_conductivity'] = kappa_eff

        return effective
```

---

## 4.6 통합 파이프라인

```python
"""
전체 워크플로우 통합 파이프라인
"""

from pathlib import Path
import numpy as np


class ElectrodeGenerationPipeline:
    """
    전극 미세구조 생성 → 메시 변환 → COMSOL 연계 통합 파이프라인
    """

    def __init__(self, config: dict):
        """
        Args:
            config: 파이프라인 설정 딕셔너리
        """
        self.config = config
        self.output_dir = Path(config.get('output_dir', './output'))
        self.output_dir.mkdir(parents=True, exist_ok=True)

    def run(self, voxel_data: np.ndarray) -> dict:
        """
        전체 파이프라인 실행

        Args:
            voxel_data: 생성된 3D 복셀 데이터 (n_phases, D, H, W) 또는 (D, H, W)

        Returns:
            결과 딕셔너리
        """
        results = {}

        # 1. 복셀 데이터 처리
        print("Step 1: Processing voxel data...")
        if voxel_data.ndim == 4:
            labels = voxel_data.argmax(axis=0)
        else:
            labels = voxel_data

        results['labels_shape'] = labels.shape

        # 2. 메시 생성
        print("Step 2: Generating mesh...")
        meshes = VoxelToMesh.multiphase_to_mesh(
            labels,
            spacing=(self.config['voxel_size'],) * 3
        )

        for phase_id, mesh in meshes.items():
            stl_path = self.output_dir / f"phase_{phase_id}.stl"
            VoxelToMesh.export_mesh(mesh, str(stl_path))
            results[f'mesh_phase_{phase_id}'] = str(stl_path)

        # 3. 메시 정제 (선택)
        if self.config.get('refine_mesh', False):
            print("Step 3: Refining mesh...")
            for phase_id, mesh in meshes.items():
                refined = MeshRefinement.smooth_mesh(mesh, iterations=5)
                refined = MeshRefinement.decimate_mesh(refined, ratio=0.5)
                refined_path = self.output_dir / f"phase_{phase_id}_refined.stl"
                VoxelToMesh.export_mesh(refined, str(refined_path))
                results[f'refined_mesh_phase_{phase_id}'] = str(refined_path)

        # 4. FEM 메시 생성 (Gmsh)
        if self.config.get('generate_fem_mesh', False):
            print("Step 4: Generating FEM mesh...")
            for phase_id in meshes.keys():
                stl_path = self.output_dir / f"phase_{phase_id}.stl"
                fem_path = self.output_dir / f"phase_{phase_id}_fem.msh"

                stats = stl_to_fem_mesh(
                    str(stl_path),
                    str(fem_path),
                    mesh_size=self.config.get('fem_mesh_size', 0.5)
                )
                results[f'fem_mesh_phase_{phase_id}'] = {
                    'path': str(fem_path),
                    'stats': stats
                }

        # 5. 물성 파일 생성
        print("Step 5: Generating property files...")
        MaterialPropertyMapper.generate_property_file(
            labels,
            self.config['voxel_size'],
            str(self.output_dir / "properties")
        )

        # 유효 물성 계산
        effective_props = MaterialPropertyMapper.calculate_effective_properties(labels)
        results['effective_properties'] = effective_props

        # 6. COMSOL 연계 (선택)
        if self.config.get('run_comsol', False):
            print("Step 6: Running COMSOL simulation...")
            # automated_comsol_workflow 호출
            pass

        print("Pipeline completed!")
        return results


# 사용 예시
if __name__ == "__main__":
    # 설정
    config = {
        'output_dir': './output/electrode_001',
        'voxel_size': 1e-6,  # 1 μm
        'refine_mesh': True,
        'generate_fem_mesh': True,
        'fem_mesh_size': 0.5e-6,  # 0.5 μm
        'run_comsol': False
    }

    # 파이프라인 생성
    pipeline = ElectrodeGenerationPipeline(config)

    # 가상 데이터 생성 (실제로는 SliceGAN 출력 사용)
    fake_voxels = np.random.randint(0, 3, size=(64, 64, 64))

    # 실행
    results = pipeline.run(fake_voxels)

    print("\nResults:")
    for key, value in results.items():
        print(f"  {key}: {value}")
```

---

## 4.7 참고 자료

### Blender 및 메시 처리

| 자료 | 링크 | 설명 |
|------|------|------|
| Blender Python API | [Docs](https://docs.blender.org/api/current/info_quickstart.html) | 공식 bpy 문서 |
| trimesh | [GitHub](https://github.com/mikedh/trimesh) | Python 메시 라이브러리 |
| PyVista | [Docs](https://docs.pyvista.org/) | 3D 시각화 및 메시 처리 |

### Gmsh 및 FEM 메싱

| 자료 | 링크 | 설명 |
|------|------|------|
| Gmsh 공식 | [gmsh.info](https://gmsh.info/) | Gmsh 공식 사이트 |
| Gmsh 튜토리얼 | [Tutorial](https://jsdokken.com/src/tutorial_gmsh.html) | Python API 튜토리얼 |

### COMSOL 연계

| 자료 | 링크 | 설명 |
|------|------|------|
| mph 라이브러리 | [Docs](https://mph.readthedocs.io/) | Python COMSOL 인터페이스 |
| COMSOL Application Library | [COMSOL](https://www.comsol.com/models) | 예제 모델 라이브러리 |

---

# 부록: 유용한 명령어 및 팁

## A. 설치 명령어 모음

```bash
# 핵심 패키지
pip install torch torchvision torchaudio
pip install numpy scipy scikit-image opencv-python

# 메시 처리
pip install trimesh pyvista vtk meshio

# Gmsh
pip install gmsh

# COMSOL 연계
pip install mph

# 설정 관리
pip install hydra-core omegaconf pyyaml

# 시각화
pip install matplotlib plotly

# Blender (독립 실행형 - 제한적)
# pip install bpy  # 또는 Blender 설치 후 내장 Python 사용
```

## B. Blender 명령줄 실행

```bash
# 헤드리스 모드로 스크립트 실행
blender --background --python script.py

# 인자 전달
blender --background --python script.py -- --input mesh.stl --output result.stl

# 특정 Python 버전 사용 (Blender 내장)
blender --background --python-expr "import sys; print(sys.version)"
```

## C. COMSOL 서버 실행

```bash
# Windows (COMSOL 설치 경로)
"C:\Program Files\COMSOL\COMSOL60\Multiphysics\bin\win64\comsolmphserver.exe"

# Linux
/usr/local/comsol60/multiphysics/bin/comsol mphserver

# macOS
/Applications/COMSOL60/Multiphysics/bin/comsol mphserver
```

---

# 문서 정보

| 항목 | 내용 |
|------|------|
| **문서 버전** | 1.0 |
| **작성일** | 2025년 1월 |
| **총 분량** | 약 2,500줄 |
| **대상 독자** | 배터리 연구자, 딥러닝 엔지니어, 시뮬레이션 엔지니어 |

---

**끝.**
